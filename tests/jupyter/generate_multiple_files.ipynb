{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Files\n",
    "\n",
    "* Given a template and a definition of the variables, generate a set of new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command found: var_uniform_int[int,1,(uniform,1,10)]\n",
      "  key: var_uniform_int\n",
      "  options: {'active': True, 'distribution': 'uniform', 'parameters': [1, 10], 'default': 1, 'type': 'int'}\n",
      "Command found: var_uniform[float,1,(uniform,0,1)]\n",
      "  key: var_uniform\n",
      "  options: {'active': True, 'distribution': 'uniform', 'parameters': [0.0, 1.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_normal[float,1,(normal,0,1)]\n",
      "  key: var_normal\n",
      "  options: {'active': True, 'distribution': 'normal', 'parameters': [0.0, 1.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_truncnormal[float,1,(truncnormal,0,1,-1, 1)]\n",
      "  key: var_truncnormal\n",
      "  options: {'active': True, 'distribution': 'truncnormal', 'parameters': [0.0, 1.0, -1.0, 1.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_lognormal[float,1,(lognormal,1,1)]\n",
      "  key: var_lognormal\n",
      "  options: {'active': True, 'distribution': 'lognormal', 'parameters': [1.0, 1.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_triangular[float,1,(triangular,0,3,1)]\n",
      "  key: var_triangular\n",
      "  options: {'active': True, 'distribution': 'triangular', 'parameters': [0.0, 3.0, 1.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_constant[float,1,(constant,2)]\n",
      "  key: var_constant\n",
      "  options: {'active': True, 'distribution': 'constant', 'parameters': [2.0], 'default': 1.0, 'type': 'float'}\n",
      "Command found: var_categorical[int,1,(categorical,{1,2,3,4},{0.1,0.1,0.2,0.6})]\n",
      "  key: var_categorical\n",
      "  options: {'active': True, 'distribution': 'categorical', 'parameters': [[1, 2, 3, 4], [0.1, 0.2, 0.4, 1.0]], 'default': 1, 'type': 'int'}\n",
      "Cheking parameters\n",
      "Building experiments\n",
      "Calculating inverse CDF\n",
      "   var_uniform_int: uniform\n",
      "   var_uniform: uniform\n",
      "   var_normal: normal\n",
      "   var_truncnormal: truncnormal\n",
      "   var_lognormal: lognormal\n",
      "   var_triangular: triangular\n",
      "   var_constant: constant\n",
      "   var_categorical: categorical\n",
      "     var_uniform_int  var_uniform  var_normal  var_truncnormal  var_lognormal  \\\n",
      "0                  2     0.563682    1.884101        -0.167044       0.944830   \n",
      "1                  6     0.621474   -2.038544        -0.261700       5.736376   \n",
      "2                 10     0.008983   -0.193989         0.658501       0.825562   \n",
      "3                  6     0.488399    0.982986         0.540793       4.484523   \n",
      "4                  4     0.751092    1.375014         0.333078       0.113579   \n",
      "..               ...          ...         ...              ...            ...   \n",
      "995                2     0.929507    0.325038        -0.311216       0.518793   \n",
      "996                6     0.231164    0.476736        -0.975534       0.714831   \n",
      "997                7     0.829325   -0.927489         0.933163       1.143285   \n",
      "998                5     0.690984    0.260918         0.940463      22.381216   \n",
      "999                6     0.069037    0.127674         0.396031       2.262889   \n",
      "\n",
      "     var_triangular  var_constant  var_categorical  \n",
      "0          0.953141           2.0                1  \n",
      "1          1.840534           2.0                4  \n",
      "2          1.138888           2.0                2  \n",
      "3          1.177206           2.0                4  \n",
      "4          1.524605           2.0                1  \n",
      "..              ...           ...              ...  \n",
      "995        1.810488           2.0                4  \n",
      "996        0.768800           2.0                3  \n",
      "997        2.440496           2.0                3  \n",
      "998        1.302489           2.0                3  \n",
      "999        0.836430           2.0                3  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "class TemplateProcessor:\n",
    "    def __init__(self, template_path, verbose=False, output_file_path=None, variables_table_path=None, all_uniform=False):\n",
    "        self.template_path = Path(template_path)\n",
    "        if not self.template_path.exists():\n",
    "            raise FileNotFoundError(f\"Template file '{self.template_path}' not found.\")\n",
    "        \n",
    "        self._verbose = verbose\n",
    "        self._all_uniform = all_uniform\n",
    "\n",
    "        self._valid_distributions = {\n",
    "            'uniform':      {'parameters':2, 'description':('minimum','maximum'), 'types':['int','float']},\n",
    "            'normal':       {'parameters':2, 'description':('mean','std_var'), 'types':['float']},\n",
    "            'truncnormal':  {'parameters':4, 'description':('mean','std_var','minimum','maximum'), 'types':['float']},\n",
    "            'lognormal':    {'parameters':2, 'description':('mean','std_var'), 'types':['float']},\n",
    "            'triangular':   {'parameters':3, 'description':('minimum','maximum','most_likelly'), 'types':['float']},\n",
    "            'constant':     {'parameters':1, 'description':('value'), 'types':['int','float','str']},\n",
    "            'categorical':  {'parameters':2, 'description':('values_list','probabilities_list'), 'types':['int','float','str']},\n",
    "            'table':        {'parameters':0, 'description':('no parameters'), 'types':['str']}\n",
    "        }\n",
    "        # std_dev from mean to define limits of normal distribution variables when using option all_uniform=True\n",
    "        self._normal_limits_as_uniform = 2.\n",
    "\n",
    "        self.variables_raw = self._extract_raw_text()\n",
    "        self.variables = self._parse_variables()\n",
    "\n",
    "        if variables_table_path is not None:\n",
    "            self.set_variables_table(variables_table_path)\n",
    "\n",
    "        self.experiments_table = None\n",
    "        self._current_distribution = None\n",
    "        if output_file_path is not None:\n",
    "            self.set_output_file(output_file_path)\n",
    "            self.generate_experiments()\n",
    "            self.create_new_files()\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.variables)\n",
    "\n",
    "    def list_valid_distributions(self):\n",
    "        for k,v in self._valid_distributions.items():\n",
    "            print(f\"'{k}'. parameters: {', '.join(v['description'])}, valid type(s): {', '.join(v['types'])}\")\n",
    "\n",
    "    def _extract_contents(self, text, open=r'\\(', close=r'\\)'):\n",
    "        pattern = f'{open}(.*?){close}'\n",
    "        matches = re.findall(pattern, text)\n",
    "        return matches\n",
    "    \n",
    "    def _custom_split(self, text, sep=',', open='{', close='}'):\n",
    "        result = []\n",
    "        current_token = ''\n",
    "        paren_count = 0\n",
    "\n",
    "        for char in text:\n",
    "            if char == sep and paren_count == 0:\n",
    "                result.append(current_token.strip())\n",
    "                current_token = ''\n",
    "            elif char == open:\n",
    "                paren_count += 1\n",
    "                current_token += char\n",
    "            elif char == close:\n",
    "                paren_count -= 1\n",
    "                current_token += char\n",
    "            else:\n",
    "                current_token += char\n",
    "\n",
    "        result.append(current_token.strip())\n",
    "        return result\n",
    "    \n",
    "    def _extract_raw_text(self):\n",
    "        variables_raw = []\n",
    "        with open(self.template_path, 'r') as file:\n",
    "            for line_num, line in enumerate(file, start=1):              \n",
    "                if line.count(r'<\\var>') != line.count('<var>'):\n",
    "                    raise ValueError(f\"Unclosed <\\\\var> <var> at line {line_num}.\")\n",
    "                parts = self._extract_contents(text=line, open=r'<\\\\var>', close=r'<var>')\n",
    "                if len(parts) > 0:\n",
    "                    for part in parts:\n",
    "                        var = part.strip()\n",
    "                        if var == '':\n",
    "                            raise ValueError(f\"Empty variable name at line {line_num}.\")\n",
    "                        variables_raw.append(var)\n",
    "        return variables_raw\n",
    "\n",
    "    def _transform_variable(self, variable, variable_type):\n",
    "        if isinstance(variable, list):\n",
    "            var = list()\n",
    "            for i in range(len(variable)):\n",
    "                var.append(self._transform_variable(variable=variable[i], variable_type=variable_type))\n",
    "                if var[-1] is None:\n",
    "                    return None\n",
    "            return var\n",
    "        else:                \n",
    "            try:\n",
    "                var_type = eval(variable_type)\n",
    "                return var_type(variable)\n",
    "            except (ValueError, TypeError, NameError):\n",
    "                return None\n",
    "\n",
    "    def _parse_distribution(self, text, var_type):\n",
    "        if text is None:\n",
    "            if self._verbose:\n",
    "                print(\"  No distribution provided. Will assume 'table'.\")\n",
    "            return 'table', list()\n",
    "\n",
    "        parameters = self._custom_split(text)\n",
    "        distribution = parameters[0].lower()\n",
    "        if distribution not in self._valid_distributions:\n",
    "            raise ValueError(f\"Invalid distribution: '{distribution}'.\")\n",
    "        parameters = parameters[1:]\n",
    "        if len(parameters) != self._valid_distributions[distribution]['parameters']:\n",
    "            raise ValueError(f\"Invalid number of parameters for distribution '{distribution}'. Expected {self._valid_distributions[distribution]['parameters']}, found {len(parameters)}.\")\n",
    "\n",
    "        if var_type is not None:\n",
    "            if var_type not in self._valid_distributions[distribution]['types']:\n",
    "                raise ValueError(f\"Invalid type ({var_type}) for distribution '{distribution}'. Valid option(s): {', '.join(self._valid_distributions[distribution]['types'])}.\")\n",
    "            \n",
    "            if distribution == 'categorical':\n",
    "                param_list = parameters[0].lstrip('{').rstrip('}').split(',')\n",
    "            else:\n",
    "                param_list = parameters\n",
    "\n",
    "            for i in range(len(param_list)):\n",
    "                new_value = self._transform_variable(variable=param_list[i], variable_type=var_type)\n",
    "                if new_value is None:\n",
    "                    raise ValueError(f\"Parameters for distribution '{distribution}' must be of type {var_type}. Cannot transform '{param_list[i]}'.\")\n",
    "                param_list[i] = new_value\n",
    "    \n",
    "            if distribution == 'categorical':\n",
    "                parameters[0] = param_list\n",
    "            else:\n",
    "                parameters = param_list\n",
    "\n",
    "        if distribution == 'categorical':\n",
    "            param_list = parameters[1].lstrip('{').rstrip('}').split(',')\n",
    "            if len(parameters[0]) != len(param_list):\n",
    "                raise ValueError(f\"Inconsistent number of values in distribution '{distribution}'. Values found: {len(parameters[0])}, associated probabilities: {len(param_list)}.\")\n",
    "            for i in range(len(param_list)):\n",
    "                new_value = self._transform_variable(variable=param_list[i], variable_type='float')\n",
    "                if new_value is None:\n",
    "                    raise ValueError(f\"Probabilities for distribution '{distribution}' must be of type float. Cannot transform '{param_list[i]}'.\")\n",
    "                param_list[i] = new_value\n",
    "            s = sum(param_list)\n",
    "            cum_list = [sum(param_list[:i+1])/s for i in range(len(param_list))]\n",
    "            parameters[1] = cum_list\n",
    "\n",
    "        return distribution, parameters\n",
    "    \n",
    "    def _check_variable_type(self, default, distribution, parameters):\n",
    "        var_type = None\n",
    "        for test_type in self._valid_distributions[distribution]['types']:\n",
    "            if var_type is None:\n",
    "                var_type = test_type\n",
    "    \n",
    "                if default is not None:\n",
    "                    default_mod = self._transform_variable(variable=default, variable_type=test_type)\n",
    "                    if default_mod is None:\n",
    "                        var_type = None\n",
    "                    else:\n",
    "                        default = default_mod\n",
    "\n",
    "                param_out = list()\n",
    "                for param in parameters:\n",
    "                    if var_type is not None:\n",
    "                        param_out.append(self._transform_variable(variable=param, variable_type=var_type))\n",
    "                        if param_out[-1] is None:\n",
    "                            var_type = None\n",
    "                \n",
    "                if var_type is not None:\n",
    "                    parameters = param_out\n",
    "\n",
    "                    if self._verbose:\n",
    "                        print(f\"  No type provided. Will assume '{var_type}'.\")\n",
    "                \n",
    "        return default, distribution, parameters, var_type\n",
    "\n",
    "    def _parse_variable_options(self, text):\n",
    "        default = None\n",
    "        var_type = None\n",
    "\n",
    "        distribution_text = self._extract_contents(text=text, open=r'\\(', close=r'\\)')\n",
    "        if len(distribution_text) > 1:\n",
    "            raise ValueError(f\"Bad distribution options format in: '{text}'. Only one distribution with ( and ) can be defined.\")\n",
    "\n",
    "        options = self._custom_split(text=text, open='(', close=')')\n",
    "        if len(distribution_text) == 1:\n",
    "            if '(' not in options[-1] or ')' not in options[-1]:\n",
    "                raise ValueError(f\"Distribution options with ( and ) must be the last information in: '{options}'.\")\n",
    "            options = options[:-1]\n",
    "            distribution_text = distribution_text[0].strip()\n",
    "        else:\n",
    "            distribution_text = None\n",
    "\n",
    "        if len(options) > 2:\n",
    "            raise ValueError(f\"Bad options format in: '{options}'. Too many options.\")\n",
    "        elif len(options) > 0:\n",
    "            if len(options) > 1 or options[0] != '':\n",
    "                default = options[-1].strip()\n",
    "                if len(options) == 2:\n",
    "                    var_type = options[0].strip()\n",
    "                    default = self._transform_variable(variable=default, variable_type=var_type)\n",
    "                    if default is None:\n",
    "                        raise ValueError(f\"Default value ({options[-1]}) must be of the defined type ({var_type}).\")\n",
    "\n",
    "        distribution, parameters = self._parse_distribution(distribution_text, var_type)\n",
    "\n",
    "        if var_type is None:\n",
    "            default, distribution, parameters, var_type = self._check_variable_type(default, distribution, parameters)\n",
    "        if var_type is None:\n",
    "            raise ValueError(f\"Couldn't find the variable type based on provided data: '{text}'. Possible type(s) for {distribution} are: {', '.join(self._valid_distributions[distribution]['types'])}.\")\n",
    "\n",
    "        return {'active': True, 'distribution': distribution, 'parameters': parameters, 'default': default, 'type': var_type}\n",
    "\n",
    "    def _parse_key(self, text):\n",
    "        key = text.split('[')[0].strip()\n",
    "        if len(key) == 0:\n",
    "            raise ValueError(f\"Undefined variable name in: '{text}'.\")\n",
    "        return key\n",
    "\n",
    "    def _parse_options(self, text):\n",
    "        options = self._extract_contents(text=text, open=r'\\[', close=r'\\]')\n",
    "        if len(options) > 1:\n",
    "            raise ValueError(f\"Bad options format in: '{text}'. Only one list with [ and ] can be defined.\")\n",
    "\n",
    "        if len(options) == 1:\n",
    "            options_dict = self._parse_variable_options(options[0])\n",
    "        else:\n",
    "            options_dict = self._parse_variable_options('')\n",
    "\n",
    "        return options_dict\n",
    "\n",
    "    def _parse_variables(self):\n",
    "        # General pattern: Variable[type, default, (distribution, par1, par2)]\n",
    "        variables = {}\n",
    "        repetition = list()\n",
    "        for text in self.variables_raw:\n",
    "            if self._verbose:\n",
    "                print(f'Command found: {text}')\n",
    "            key = self._parse_key(text)\n",
    "            if key in variables:\n",
    "                if self._verbose and key not in repetition:\n",
    "                    print(f'  key {key} found more than once. Ignoring options in repetitions.')\n",
    "                    repetition.append(key)\n",
    "            else:\n",
    "                options = self._parse_options(text)\n",
    "                variables[key] = options\n",
    "                if self._verbose:\n",
    "                    print(f'  key: {key}')\n",
    "                    print(f'  options: {options}')\n",
    "        return variables\n",
    "\n",
    "    def set_output_file(self, output_file_path):\n",
    "        if output_file_path is None:\n",
    "            self.output_file_path = None\n",
    "        else:\n",
    "            try:\n",
    "                self.output_file_path = Path(output_file_path)\n",
    "            except (ValueError, TypeError, NameError):\n",
    "                self.output_file_path = None\n",
    "                raise ValueError(f\"Invalid file path: {str(output_file_path)}\")\n",
    "\n",
    "    def set_variables_table(self, variables_table_path):\n",
    "        if not Path(variables_table_path).exists():\n",
    "            print(f\"CSV file '{variables_table_path}' not found.\")\n",
    "        else:\n",
    "            try:\n",
    "                df = pd.read_csv(variables_table_path, skipinitialspace=True)\n",
    "                for key in df.columns:\n",
    "                    if key not in self.variables:\n",
    "                        print(f\"Variable '{key}' not found in template. Will ignore data.\")\n",
    "                        continue\n",
    "                    if self.variables[key]['distribution'] != 'table':\n",
    "                        print(f\"Variable '{key}' already has a distribution. Will ignore data.\")\n",
    "                        continue\n",
    "                    self.variables[key]['values'] = list(df[key])\n",
    "            except (ValueError, TypeError, NameError):\n",
    "                print(f'Error reading variables table file: {variables_table_path}')\n",
    "\n",
    "    def _check_generate_experiments(self, n_samples=0):\n",
    "        tables_n_values = list()\n",
    "        for data in self.variables.values():\n",
    "            if data.get('distribution', False) == 'table':\n",
    "                tables_n_values.append(len(data.get('values', [])))\n",
    "\n",
    "        if len(tables_n_values) > 0:\n",
    "            if not min(tables_n_values) == max(tables_n_values):\n",
    "                print(f\"Number of entries in 'table' variables is inconsistent, ranging from {min(tables_n_values)} to {max(tables_n_values)}. Cannot continue.\")\n",
    "                return None         \n",
    "            tables_n_values = tables_n_values[0]\n",
    "            if tables_n_values == 0:\n",
    "                print(\"No values found for 'table' variables. Cannot continue.\")\n",
    "                return None\n",
    "        else:\n",
    "            tables_n_values = n_samples\n",
    "\n",
    "        if n_samples < 1 and tables_n_values > 0:\n",
    "            n_samples = tables_n_values\n",
    "        elif n_samples < 1:\n",
    "            print(f\"Requested sample size ({n_samples}) is smaller than minimum (1). Cannot continue.\")\n",
    "            return None\n",
    "        elif tables_n_values != n_samples:\n",
    "            print(f\"Number of values in 'table' variables ({tables_n_values}) is different from the requested sample size ({n_samples}). Cannot continue.\")\n",
    "            return None\n",
    "        \n",
    "        return n_samples\n",
    "\n",
    "    def _InvCDF(self, probability, data, all_uniform):\n",
    "        if min(probability) < 0:\n",
    "            raise ValueError(\"Probability lower than zero!\")\n",
    "        if max(probability) > 1:\n",
    "            raise ValueError(\"Probability larger than one!\")\n",
    "\n",
    "        distribution = data['distribution']\n",
    "        parameters = data['parameters']\n",
    "        \n",
    "        if distribution == 'constant':\n",
    "            return parameters[0]\n",
    "        \n",
    "        elif distribution == 'categorical':\n",
    "            if all_uniform:\n",
    "                n = len(parameters[0])\n",
    "                p_cum_list = [(i+1) / n for i in range(n)]\n",
    "            else:\n",
    "                p_cum_list = parameters[1]\n",
    "\n",
    "            def cat_prob(x):\n",
    "                for i, p in enumerate(p_cum_list):\n",
    "                    if p >= x:\n",
    "                        return parameters[0][i]\n",
    "                raise ValueError(\"Error in categorical probabilities!\")\n",
    "            vec_cat_prob = np.vectorize(cat_prob)\n",
    "            return vec_cat_prob(probability)\n",
    "\n",
    "        elif distribution == 'uniform' or (distribution == 'triangular' and all_uniform):\n",
    "            a = parameters[0]\n",
    "            b = parameters[1]\n",
    "            if isinstance(a, int) and isinstance(b, int):\n",
    "                n_int = b - a + 1\n",
    "                return a + np.int32(np.floor(probability * n_int))\n",
    "            else:\n",
    "                return a + probability * (b - a)\n",
    "            \n",
    "        elif distribution == 'triangular':\n",
    "            # a = parameters[0]\n",
    "            # b = parameters[1]\n",
    "            # c = parameters[2]\n",
    "\n",
    "            loc = parameters[0]\n",
    "            scale = parameters[1] - parameters[0]\n",
    "            c = (parameters[2] - parameters[0]) / scale\n",
    "\n",
    "            return stats.triang.ppf(probability, c, loc=loc, scale=scale)\n",
    "\n",
    "            # def tri_prob(x):\n",
    "            #     if x <= (c - a) / (b - a):\n",
    "            #         return a + (b - a) * (x * (b - a) * (c - a))**0.5\n",
    "            #     else:\n",
    "            #         return b - (b - a) * ((1 - x) * (b - a) * (b - c))**0.5\n",
    "            # vec_tri_prob = np.vectorize(tri_prob)\n",
    "            # return vec_tri_prob(probability)\n",
    "            \n",
    "        elif distribution == 'normal':\n",
    "            mean = parameters[0]\n",
    "            std_dev = parameters[1]\n",
    "            if all_uniform:\n",
    "                a = mean - std_dev * self._normal_limits_as_uniform\n",
    "                b = mean + std_dev * self._normal_limits_as_uniform\n",
    "                return a + probability * (b - a)\n",
    "            else:\n",
    "                return stats.norm.ppf(probability, loc=mean, scale=std_dev)\n",
    "        \n",
    "        elif distribution == 'truncnormal':\n",
    "            mean = parameters[0]\n",
    "            std_dev = parameters[1]\n",
    "            a = parameters[2]\n",
    "            b = parameters[3]\n",
    "            if all_uniform:\n",
    "                return a + probability * (b - a)\n",
    "            else:\n",
    "                return stats.truncnorm.ppf(probability, (a - mean) / std_dev, (b - mean) / std_dev, loc=mean, scale=std_dev)\n",
    "        \n",
    "        elif distribution == 'lognormal':\n",
    "            mean = parameters[0]\n",
    "            std_dev = parameters[1]\n",
    "            if all_uniform:\n",
    "                a = np.log(mean) - std_dev * self._normal_limits_as_uniform\n",
    "                b = np.log(mean) + std_dev * self._normal_limits_as_uniform\n",
    "                return np.exp(a + probability * (b - a))\n",
    "            else:\n",
    "                return stats.lognorm.ppf(probability, s=std_dev, scale=mean)\n",
    "        \n",
    "        raise ValueError(f\"Unknown distribution: {distribution}.\")\n",
    "        \n",
    "    def set_variable_active(self, variable, active=True):\n",
    "        if variable not in self.variables:\n",
    "            raise ValueError(f\"Unknown variable: {variable}.\")\n",
    "        if not active and self.variables[variable]['default'] is None:\n",
    "            raise ValueError(f\"Cannot deactivate a variable without a default value: {variable}.\")\n",
    "        self.variables[variable]['default'] = active\n",
    "\n",
    "    def generate_experiments(self, n_samples=0, all_uniform=None):\n",
    "        if self._verbose:\n",
    "            print('Cheking parameters')\n",
    "        n_samples = self._check_generate_experiments(n_samples=n_samples)\n",
    "        if n_samples < 1:\n",
    "            self.experiment_table = None\n",
    "            return\n",
    "        \n",
    "        if all_uniform is None:\n",
    "            all_uniform = self._all_uniform\n",
    "\n",
    "        if self._verbose:\n",
    "            print('Building experiments')\n",
    "        samples = lhs(len(self.variables), samples=n_samples, criterion='maximin', iterations=5)\n",
    "\n",
    "        if self._verbose:\n",
    "            print('Calculating inverse CDF')\n",
    "        df = pd.DataFrame()\n",
    "        for column_index, var in enumerate(self.variables):\n",
    "            data = self.variables[var]\n",
    "            if self._verbose:\n",
    "                print(f'   {var}: {data['distribution']}')\n",
    "            if not data['active']:\n",
    "                df[var] = [data['default']] * n_samples\n",
    "            elif data['distribution'] == 'table':\n",
    "                df[var] = data['values']\n",
    "            else:\n",
    "                df[var] = self._InvCDF(samples[:, column_index], data, all_uniform)\n",
    "        self.experiments_table = df\n",
    "        \n",
    "    def create_new_files(self, output_file_path=None):\n",
    "        if output_file_path is not None:\n",
    "            self.set_output_file(output_file_path)\n",
    "        if self.output_file_path is None:\n",
    "            print('Output file not defined. Cannot continue.')\n",
    "            return\n",
    "        if self.experiment_table is None:\n",
    "            self.generate_experiments()\n",
    "            if self.experiment_table is None:\n",
    "                print('Experiments table could not be created. Cannot continue.')\n",
    "                return\n",
    "              \n",
    "\n",
    "        pass\n",
    "\n",
    "template = TemplateProcessor(template_path=r'..\\template\\no_errors_distributions.dat',\n",
    "                             verbose=True)\n",
    "template.generate_experiments(1000)\n",
    "print(template.experiments_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.experiments_table.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var1': {'active': True, 'distribution': 'table', 'parameters': [], 'default': '17', 'type': 'str', 'values': ['0', '1', 'a']}, 'var2': {'active': True, 'distribution': 'table', 'parameters': [], 'default': None, 'type': 'str', 'values': ['1', '1', 'b']}, 'var3': {'active': True, 'distribution': 'table', 'parameters': [], 'default': None, 'type': 'str', 'values': ['2', '1', 'c']}, 'var4': {'active': True, 'distribution': 'table', 'parameters': [], 'default': None, 'type': 'str', 'values': ['3', '1', 'd']}}\n"
     ]
    }
   ],
   "source": [
    "template = TemplateProcessor(template_path=r'..\\template\\no_errors_table_variables.dat',\n",
    "                             variables_table_path=r'..\\template\\no_errors_table_variables.csv',\n",
    "                             verbose=False)\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Errors Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command found: No_Default\n",
      "  No distribution provided. Will assume 'table'.\n",
      "  No type provided. Will assume 'str'.\n",
      "  key: No_Default\n",
      "  options: {'active': True, 'distribution': 'table', 'parameters': [], 'default': None, 'type': 'str'}\n",
      "Command found: With_Default_12[12]\n",
      "  No distribution provided. Will assume 'table'.\n",
      "  No type provided. Will assume 'str'.\n",
      "  key: With_Default_12\n",
      "  options: {'active': True, 'distribution': 'table', 'parameters': [], 'default': '12', 'type': 'str'}\n",
      "Command found: With_Type_int[int,42]\n",
      "  No distribution provided. Will assume 'table'.\n",
      "  key: With_Type_int\n",
      "  options: {'active': True, 'distribution': 'table', 'parameters': [], 'default': 42, 'type': 'int'}\n",
      "Command found: normal_variable[float,0.5,(normal,0, 2.5)]\n",
      "  key: normal_variable\n",
      "  options: {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': 0.5, 'type': 'float'}\n",
      "Command found: normal_variable_no_type[0.5,(normal,0, 2.5)]\n",
      "  No type provided. Will assume 'float'.\n",
      "  key: normal_variable_no_type\n",
      "  options: {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': 0.5, 'type': 'float'}\n",
      "Command found: List_int[int,3,(categorical,{1,3,7,-12},{0.2,0.15,0.25,0.400})]\n",
      "[0.2, 0.15, 0.25, 0.4]\n",
      "  key: List_int\n",
      "  options: {'active': True, 'distribution': 'categorical', 'parameters': [[1, 3, 7, -12], [0.2, 0.35, 0.6, 1.0]], 'default': 3, 'type': 'int'}\n",
      "Command found: List_float[float,7.,(categorical,{1,3,7,-12},{0.2,0.15,0.25,0.400})]\n",
      "[0.2, 0.15, 0.25, 0.4]\n",
      "  key: List_float\n",
      "  options: {'active': True, 'distribution': 'categorical', 'parameters': [[1.0, 3.0, 7.0, -12.0], [0.2, 0.35, 0.6, 1.0]], 'default': 7.0, 'type': 'float'}\n",
      "Command found: normal_no_type_float[(normal,0, 2.5)]\n",
      "  No type provided. Will assume 'float'.\n",
      "  key: normal_no_type_float\n",
      "  options: {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': None, 'type': 'float'}\n",
      "Command found: uniform_no_type_int[(uniform,0, 12)]\n",
      "  No type provided. Will assume 'int'.\n",
      "  key: uniform_no_type_int\n",
      "  options: {'active': True, 'distribution': 'uniform', 'parameters': [0, 12], 'default': None, 'type': 'int'}\n",
      "Command found: uniform_no_type_float[(uniform,0., 12.)]\n",
      "  No type provided. Will assume 'float'.\n",
      "  key: uniform_no_type_float\n",
      "  options: {'active': True, 'distribution': 'uniform', 'parameters': [0.0, 12.0], 'default': None, 'type': 'float'}\n",
      "Command found: constant_no_type_str[(constant,0)]\n",
      "  No type provided. Will assume 'int'.\n",
      "  key: constant_no_type_str\n",
      "  options: {'active': True, 'distribution': 'constant', 'parameters': [0], 'default': None, 'type': 'int'}\n"
     ]
    }
   ],
   "source": [
    "template = TemplateProcessor(template_path=r'..\\template\\no_errors.dat',\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Catching Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "def process_temporary_file(text):\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n",
    "            temp_file.write(text)\n",
    "            temp_file_path = Path(temp_file.name)\n",
    "        \n",
    "        template = TemplateProcessor(template_path=temp_file_path, verbose=False)\n",
    "        return template\n",
    "\n",
    "    finally:\n",
    "        temp_file_path.unlink()\n",
    "\n",
    "def test_function(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    return wrapper\n",
    "\n",
    "def test_template_error(text):\n",
    "    template = process_temporary_file(text)\n",
    "    return template\n",
    "\n",
    "@test_function\n",
    "def test_parse(text):\n",
    "    return test_template_error(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no error: <\\var>invalid_var[1.5, (normal,0, 2.5)]<var>\n",
      "    {'invalid_var': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': 1.5, 'type': 'float'}}\n",
      "\n",
      "bogus text 1: <\\var>invalid_var[1.5, (normal,0,2.)ABC]<var>\n",
      "    {'invalid_var': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.0], 'default': 1.5, 'type': 'float'}}\n",
      "\n",
      "bogus text 2: <\\var>invalid_var[1.5, (normal,0,2.), ABC]<var>\n",
      "    Error: Distribution options with ( and ) must be the last information in: '['1.5', '(normal,0,2.)', 'ABC']'.\n",
      "\n",
      "bogus text 3: <\\var>invalid_var[1.5, (normal,0,2.)]ABC<var>\n",
      "    {'invalid_var': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.0], 'default': 1.5, 'type': 'float'}}\n",
      "\n",
      "bogus text 4: <\\var>invalid_var[1.5, (normal,0,2.)], ABC<var>\n",
      "    {'invalid_var': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.0], 'default': 1.5, 'type': 'float'}}\n",
      "\n",
      "too few parameters: <\\var>invalid_var[(normal,0)]<var>\n",
      "    Error: Invalid number of parameters for distribution 'normal'. Expected 2, found 1.\n",
      "\n",
      "too many parameters: <\\var>invalid_var[(normal,0, 2.5, 7)]<var>\n",
      "    Error: Invalid number of parameters for distribution 'normal'. Expected 2, found 3.\n",
      "\n",
      "invalid distribution: <\\var>invalid_var[(nomal,0, 2.5)]<var>\n",
      "    Error: Invalid distribution: 'nomal'.\n",
      "\n",
      "missing comma 1: <\\var>invalid_var[float 1.5, (normal,0, 2.5)]<var>\n",
      "    Error: Couldn't find the variable type based on provided data: 'float 1.5, (normal,0, 2.5)'. Possible type(s) for normal are: float.\n",
      "\n",
      "missing comma 2: <\\var>invalid_var[float, 1.5 (normal,0, 2.5)]<var>\n",
      "    Error: Couldn't find the variable type based on provided data: 'float, 1.5 (normal,0, 2.5)'. Possible type(s) for normal are: float.\n",
      "\n",
      "missing comma 3: <\\var>invalid_var[float, 1.5, (normal 0, 2.5)]<var>\n",
      "    Error: Invalid distribution: 'normal 0'.\n",
      "\n",
      "missing comma 4: <\\var>invalid_var[float, 1.5, (normal,0 2.5)]<var>\n",
      "    Error: Invalid number of parameters for distribution 'normal'. Expected 2, found 1.\n",
      "\n",
      "missing comma 5: <\\var>invalid_var,float[(normal,0, 2.5)]<var>\n",
      "    {'invalid_var,float': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': None, 'type': 'float'}}\n",
      "\n",
      "missing comma 6: <\\var>invalid_var, 1.5 [(normal,0, 2.5)]<var>\n",
      "    {'invalid_var, 1.5': {'active': True, 'distribution': 'normal', 'parameters': [0.0, 2.5], 'default': None, 'type': 'float'}}\n",
      "\n",
      "type inconsistency: <\\var>invalid_var[str, 1.5, (normal,0, 2.5)]<var>\n",
      "    Error: Invalid type (str) for distribution 'normal'. Valid option(s): float.\n",
      "\n",
      "unclosed var: <\\var>invalid_var[1.5, (normal,0, 2.5)]var>\n",
      "    Error: Unclosed <\\var> <var> at line 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_list = {\n",
    "    'no error': r'<\\var>invalid_var[1.5, (normal,0, 2.5)]<var>',\n",
    "    'bogus text 1': r'<\\var>invalid_var[1.5, (normal,0,2.)ABC]<var>',\n",
    "    'bogus text 2': r'<\\var>invalid_var[1.5, (normal,0,2.), ABC]<var>',\n",
    "    'bogus text 3': r'<\\var>invalid_var[1.5, (normal,0,2.)]ABC<var>',\n",
    "    'bogus text 4': r'<\\var>invalid_var[1.5, (normal,0,2.)], ABC<var>',\n",
    "    'too few parameters': r'<\\var>invalid_var[(normal,0)]<var>',\n",
    "    'too many parameters': r'<\\var>invalid_var[(normal,0, 2.5, 7)]<var>',\n",
    "    'invalid distribution': r'<\\var>invalid_var[(nomal,0, 2.5)]<var>',\n",
    "    'missing comma 1': r'<\\var>invalid_var[float 1.5, (normal,0, 2.5)]<var>',\n",
    "    'missing comma 2': r'<\\var>invalid_var[float, 1.5 (normal,0, 2.5)]<var>',\n",
    "    'missing comma 3': r'<\\var>invalid_var[float, 1.5, (normal 0, 2.5)]<var>',\n",
    "    'missing comma 4': r'<\\var>invalid_var[float, 1.5, (normal,0 2.5)]<var>',\n",
    "    'missing comma 5': r'<\\var>invalid_var,float[(normal,0, 2.5)]<var>',\n",
    "    'missing comma 6': r'<\\var>invalid_var, 1.5 [(normal,0, 2.5)]<var>',\n",
    "    'type inconsistency': r'<\\var>invalid_var[str, 1.5, (normal,0, 2.5)]<var>',\n",
    "    'unclosed var': r'<\\var>invalid_var[1.5, (normal,0, 2.5)]var>',\n",
    "}\n",
    "\n",
    "for k,v in error_list.items():\n",
    "    print(f'{k}: {v}')\n",
    "    print('    '+str(test_parse(v)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
