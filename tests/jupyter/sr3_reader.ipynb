{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR3 Reader\n",
    "\n",
    "* Reads data from SR3 file (HDF).\n",
    "* Return groups, wells, special and grid properties list.\n",
    "* Return 2D and 3D Time vector.\n",
    "* Return a 2D or 3D property.\n",
    "* Save all data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Groups in the HDF file:\n",
      "  General\n",
      "  SpatialProperties\n",
      "  Tables\n",
      "  TimeSeries\n",
      "\n",
      "All Groups in the HDF file:\n",
      "   General\t<class 'h5py._hl.group.Group'>\n",
      "   General/ComponentTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/EventTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/HistoryTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/MasterTimeTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/NameRecordTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/TableAssociations\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitConversionTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitsTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/BKRGCL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRGRL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWIRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSLCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/GRID/BLOCKDEPTH\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKPVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKSIZE\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICNTDR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTBC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTGN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPB\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS1\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS2\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTFR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTGT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTID\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTJD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTKD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTZA\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTAC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTBT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTCS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ISECTGEOM\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/NODES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/WELLRADIUS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/KRSETN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/MODBVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/NET%2FGROSS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCGMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWSHF\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/POR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000009/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/Statistics\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000/GO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/GroupTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/LAYERS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/LayerTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SECTORS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SPECIAL HISTORY/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/WELLS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/OperatingMode\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/WellTable\t<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r') as file:\n",
    "    print(\"Main Groups in the HDF file:\")\n",
    "    for dataset in file.keys():\n",
    "        print(f'  {dataset}')\n",
    "\n",
    "    print(\"\\nAll Groups in the HDF file:\")\n",
    "    def get_type(name):\n",
    "        print(f'   {name:}\\t{type(file[name])}')\n",
    "    file.visit(get_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/MasterTimeTable']\n",
    "day_list = {number:days for (number,days) in zip(dataset['Index'], dataset['Offset in days'])}\n",
    "\n",
    "def parse_date(date):\n",
    "    date_string = str(date)\n",
    "    integer_part = int(date_string.split('.')[0])\n",
    "    decimal_part = float(\"0.\" + date_string.split('.')[1])\n",
    "\n",
    "    parsed_date = datetime.strptime(str(integer_part), \"%Y%m%d\")\n",
    "    fraction_of_day = timedelta(days=decimal_part)\n",
    "    return parsed_date + fraction_of_day\n",
    "\n",
    "dataset = f['General/MasterTimeTable']\n",
    "date_list = {number:parse_date(date) for (number,date) in zip(dataset['Index'], dataset['Date'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/UnitsTable']\n",
    "unit_list = {number:{'internal':in_name.decode(), 'current':out_name.decode(), 'conversion':dict()} for (number,in_name,out_name) in zip(dataset['Index'],dataset['Internal Unit'],dataset['Output Unit'])}\n",
    "\n",
    "dataset = f['General/UnitConversionTable']\n",
    "for (number, name, gain, offset) in zip(dataset['Dimensionality'],dataset['Unit Name'],dataset['Gain'],dataset['Offset']):\n",
    "    unit_list[number]['conversion'][name.decode()] = (1./gain, offset * (-1.))\n",
    "\n",
    "for d in unit_list.values():\n",
    "    if d['internal'] != d['current']:\n",
    "        gain, offset = d['conversion'][d['internal']]\n",
    "        for k in d['conversion']:\n",
    "            g, o = d['conversion'][k]\n",
    "            d['conversion'][k] = (g / gain, o - offset)\n",
    "\n",
    "def set_current_unit(dimensionality, unit):\n",
    "    if unit not in unit_list[dimensionality]['conversion']:\n",
    "        raise ValueError(f'{unit} is not a valid unit for the current dimension.')\n",
    "    unit_list[dimensionality]['current'] = unit\n",
    "\n",
    "def unit_conversion(value, dimensionality, unit=None):\n",
    "    if unit is None:\n",
    "        unit = unit_list[dimensionality]['current']\n",
    "    if unit == unit_list[dimensionality]['internal']:\n",
    "        return value\n",
    "    gain, offset = unit_list[dimensionality]['conversion'][unit]\n",
    "    if gain == 1. and offset == 0.:\n",
    "        return value\n",
    "    else:\n",
    "        return value * gain + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/ComponentTable']\n",
    "component_list = {(number+1):name[0].decode() for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "def replace_components_property_list(property_list):\n",
    "    pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    def replace(match):\n",
    "        number = int(match.group(1))\n",
    "        return f'({str(component_list.get(number, match.group(1)))})'\n",
    "    return {pattern.sub(replace, k):v for k,v in property_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/NameRecordTable']\n",
    "property_list = dict()\n",
    "for (keyword,name,long_name,dimensionality) in zip(dataset['Keyword'],dataset['Name'],dataset['Long Name'],dataset['Dimensionality']):\n",
    "    if keyword != '':\n",
    "        keyword = keyword.decode()\n",
    "        name = name.decode()\n",
    "        long_name = long_name.decode()\n",
    "        dimensionality = dimensionality.decode()\n",
    "        if keyword[-2:] == '$C':\n",
    "            for c in component_list.values():\n",
    "                property_list[f'{keyword[:-2]}({c})'] = {'name':name.replace('$C', f' ({c})'), 'long name':long_name.replace('$C', f' ({c})'), 'dimensionality_string':dimensionality}\n",
    "        else:\n",
    "            property_list[keyword] = {'name':name, 'long name':long_name, 'dimensionality_string':dimensionality}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Formulas\n",
    "* Basic\n",
    "    * 1035: sum (2 parameters)\n",
    "    * 1037: sum (3 parameters)\n",
    "\n",
    "* Time derivatives\n",
    "    * 1040: derivative (1 parameter)\n",
    "    * 1045: monthly derivative (1 parameter)\n",
    "    * 1046: quarterly derivative (1 parameter)\n",
    "    * 1047: yearly derivative (1 parameter)\n",
    "    * 1048: daily derivative (1 parameter)\n",
    "    * 1049: weekly derivative (1 parameter)\n",
    "\n",
    "* Percentage\n",
    "    * 1055: A*100 (1 parameter)\n",
    "\n",
    "* Division\n",
    "    * 1060: division (2 parameters)\n",
    "    * 1062: division * 100 (2 parameters) <= used with on-fraction\n",
    "\n",
    "    * 1080: division (2 parameters)\n",
    "\n",
    "* Previous month\n",
    "    * 1121: monthly derivative of previous month (1 parameter)\n",
    "    * 1122: yearly derivative of previous month (1 parameter)\n",
    "\n",
    "* Grid properties(?)\n",
    "    * 1130: A*grid height (1 parameter)\n",
    "    * 1140: A/(B*C) ? (3 parameters)\n",
    "    * 1160: A*B (2 parameters)\n",
    "    * 1200: ternary (2 parameters)\n",
    "    * 1210: sum over layers (1 parameter)\n",
    "\n",
    "* Per sector\n",
    "    * 1110: ??? (1 parameter) <= per sector\n",
    "    * 1245: ??? (1 parameter) <= per sector\n",
    "    * 1246: derivative of 1245 (1 parameter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_from_dimensionality(dimensionality_string):\n",
    "    if dimensionality_string == '':\n",
    "        return ''\n",
    "    unit = ''\n",
    "    if dimensionality_string[0] == '-':\n",
    "        unit = '1'\n",
    "    d = ''\n",
    "    for c in dimensionality_string:\n",
    "        if c == '|':\n",
    "            unit = unit + unit_list[int(d)]['current']\n",
    "            d = ''\n",
    "        elif c == '-':\n",
    "            unit = unit + '/'\n",
    "        else:\n",
    "            d = d + c\n",
    "    return unit\n",
    "\n",
    "def unit_from_property(property_):\n",
    "    return unit_from_dimensionality(property_list[property_]['dimensionality_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/WELLS/Origins']\n",
    "well_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/WellTable']\n",
    "well_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Variables']\n",
    "well_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "well_property_list = replace_components_property_list(well_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Timesteps']\n",
    "well_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "well_day_list = [day_list[ts] for ts in well_timestep_list.values()]\n",
    "well_date_list = [date_list[ts] for ts in well_timestep_list.values()]\n",
    "\n",
    "def get_well_property(property_name, well_name):\n",
    "    dataset = f['TimeSeries/WELLS/Data']\n",
    "    return dataset[:,well_property_list[property_name],well_list[well_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/GROUPS/Origins']\n",
    "group_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/GroupTable']\n",
    "group_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Variables']\n",
    "group_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "group_property_list = replace_components_property_list(group_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Timesteps']\n",
    "group_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "group_day_list = [day_list[ts] for ts in group_timestep_list.values()]\n",
    "group_date_list = [date_list[ts] for ts in group_timestep_list.values()]\n",
    "\n",
    "def get_group_property(property_name, group_name):\n",
    "    dataset = f['TimeSeries/GROUPS/Data']\n",
    "    return dataset[:,group_property_list[property_name],group_list[group_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/LAYERS/Origins']\n",
    "layer_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_parent = {f'{parent.decode()}{{{name.decode()}}}':parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_connection = {f'{parent.decode()}{{{name.decode()}}}':connection for (name,parent,connection) in zip(dataset['Name'], dataset['Parent'], dataset['Connect To'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Variables']\n",
    "layer_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "layer_property_list = replace_components_property_list(layer_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Timesteps']\n",
    "layer_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "layer_day_list = [day_list[ts] for ts in layer_timestep_list.values()]\n",
    "layer_date_list = [date_list[ts] for ts in layer_timestep_list.values()]\n",
    "\n",
    "def get_layer_property(property_name, layer_name):\n",
    "    dataset = f['TimeSeries/LAYERS/Data']\n",
    "    return dataset[:,layer_property_list[property_name],layer_list[layer_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SECTORS/Origins']\n",
    "sector_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Variables']\n",
    "sector_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "sector_property_list = replace_components_property_list(sector_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Timesteps']\n",
    "sector_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "sector_day_list = [day_list[ts] for ts in sector_timestep_list.values()]\n",
    "sector_date_list = [date_list[ts] for ts in sector_timestep_list.values()]\n",
    "\n",
    "def get_sector_property(property_name, sector_name):\n",
    "    dataset = f['TimeSeries/SECTORS/Data']\n",
    "    return dataset[:,sector_property_list[property_name],sector_list[sector_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SPECIAL HISTORY/Variables']\n",
    "special_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "dataset = f['TimeSeries/SPECIAL HISTORY/Timesteps']\n",
    "special_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "special_property_list = replace_components_property_list(special_property_list)\n",
    "\n",
    "special_day_list = [day_list[ts] for ts in special_timestep_list.values()]\n",
    "special_date_list = [date_list[ts] for ts in special_timestep_list.values()]\n",
    "\n",
    "def get_special_property(property_name):\n",
    "    dataset = f['TimeSeries/SPECIAL HISTORY/Data']\n",
    "    return dataset[:,special_property_list[property_name],0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
