{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR3 Reader\n",
    "\n",
    "* Reads data from SR3 file (HDF).\n",
    "* Return groups, wells, special and grid properties list.\n",
    "* Return 2D and 3D Time vector.\n",
    "* Return a 2D or 3D property.\n",
    "* Save all data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Groups in the HDF file:\n",
      "  General\n",
      "  SpatialProperties\n",
      "  Tables\n",
      "  TimeSeries\n",
      "\n",
      "All Groups in the HDF file:\n",
      "   General\t<class 'h5py._hl.group.Group'>\n",
      "   General/ComponentTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/EventTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/HistoryTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/MasterTimeTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/NameRecordTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/TableAssociations\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitConversionTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitsTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/BKRGCL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRGRL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWIRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSLCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/GRID/BLOCKDEPTH\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKPVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKSIZE\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICNTDR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTBC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTGN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPB\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS1\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS2\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTFR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTGT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTID\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTJD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTKD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTZA\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTAC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTBT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTCS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ISECTGEOM\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/NODES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/WELLRADIUS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/KRSETN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/MODBVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/NET%2FGROSS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCGMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWSHF\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/POR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000009/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/Statistics\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000/GO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/GroupTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/LAYERS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/LayerTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SECTORS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SPECIAL HISTORY/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/WELLS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/OperatingMode\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/WellTable\t<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r') as file:\n",
    "    print(\"Main Groups in the HDF file:\")\n",
    "    for dataset in file.keys():\n",
    "        print(f'  {dataset}')\n",
    "\n",
    "    print(\"\\nAll Groups in the HDF file:\")\n",
    "    def get_type(name):\n",
    "        print(f'   {name:}\\t{type(file[name])}')\n",
    "    file.visit(get_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/MasterTimeTable']\n",
    "day_list = {number:days for (number,days) in zip(dataset['Index'], dataset['Offset in days'])}\n",
    "\n",
    "def parse_date(date):\n",
    "    date_string = str(date)\n",
    "    integer_part = int(date_string.split('.')[0])\n",
    "    decimal_part = float(\"0.\" + date_string.split('.')[1])\n",
    "\n",
    "    parsed_date = datetime.strptime(str(integer_part), \"%Y%m%d\")\n",
    "    fraction_of_day = timedelta(days=decimal_part)\n",
    "    return parsed_date + fraction_of_day\n",
    "\n",
    "dataset = f['General/MasterTimeTable']\n",
    "date_list = {number:parse_date(date) for (number,date) in zip(dataset['Index'], dataset['Date'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/UnitsTable']\n",
    "unit_list = {number:{'internal':in_name.decode(), 'current':out_name.decode(), 'conversion':dict()} for (number,in_name,out_name) in zip(dataset['Index'],dataset['Internal Unit'],dataset['Output Unit'])}\n",
    "\n",
    "dataset = f['General/UnitConversionTable']\n",
    "for (number, name, gain, offset) in zip(dataset['Dimensionality'],dataset['Unit Name'],dataset['Gain'],dataset['Offset']):\n",
    "    unit_list[number]['conversion'][name.decode()] = (1./gain, offset * (-1.))\n",
    "\n",
    "for d in unit_list.values():\n",
    "    if d['internal'] != d['current']:\n",
    "        gain, offset = d['conversion'][d['internal']]\n",
    "        for k in d['conversion']:\n",
    "            g, o = d['conversion'][k]\n",
    "            d['conversion'][k] = (g / gain, o - offset)\n",
    "\n",
    "def set_current_unit(dimensionality, unit):\n",
    "    if unit not in unit_list[dimensionality]['conversion']:\n",
    "        raise ValueError(f'{unit} is not a valid unit for the current dimension.')\n",
    "    unit_list[dimensionality]['current'] = unit\n",
    "\n",
    "def unit_conversion(value, dimensionality, unit=None):\n",
    "    if unit is None:\n",
    "        unit = unit_list[dimensionality]['current']\n",
    "    if unit == unit_list[dimensionality]['internal']:\n",
    "        return value\n",
    "    gain, offset = unit_list[dimensionality]['conversion'][unit]\n",
    "    if gain == 1. and offset == 0.:\n",
    "        return value\n",
    "    else:\n",
    "        return value * gain + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/ComponentTable']\n",
    "component_list = {(number+1):name[0].decode() for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "def replace_components_property_list(property_list):\n",
    "    pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    def replace(match):\n",
    "        number = int(match.group(1))\n",
    "        return f'({str(component_list.get(number, match.group(1)))})'\n",
    "    return {pattern.sub(replace, k):v for k,v in property_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/NameRecordTable']\n",
    "property_list = dict()\n",
    "for (keyword,name,long_name,dimensionality) in zip(dataset['Keyword'],dataset['Name'],dataset['Long Name'],dataset['Dimensionality']):\n",
    "    if keyword != '':\n",
    "        keyword = keyword.decode()\n",
    "        name = name.decode()\n",
    "        long_name = long_name.decode()\n",
    "        dimensionality = dimensionality.decode()\n",
    "        if keyword[-2:] == '$C':\n",
    "            for c in component_list.values():\n",
    "                property_list[f'{keyword[:-2]}({c})'] = {'name':name.replace('$C', f' ({c})'), 'long name':long_name.replace('$C', f' ({c})'), 'dimensionality_string':dimensionality}\n",
    "        else:\n",
    "            property_list[keyword] = {'name':name, 'long name':long_name, 'dimensionality_string':dimensionality}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Formulas\n",
    "* Basic\n",
    "    * 1035: sum (2 parameters)\n",
    "    * 1037: sum (3 parameters)\n",
    "\n",
    "* Time derivatives\n",
    "    * 1040: derivative (1 parameter)\n",
    "    * 1045: monthly derivative (1 parameter)\n",
    "    * 1046: quarterly derivative (1 parameter)\n",
    "    * 1047: yearly derivative (1 parameter)\n",
    "    * 1048: daily derivative (1 parameter)\n",
    "    * 1049: weekly derivative (1 parameter)\n",
    "\n",
    "* Percentage\n",
    "    * 1055: A*100 (1 parameter)\n",
    "\n",
    "* Division\n",
    "    * 1060: division (2 parameters)\n",
    "    * 1062: division * 100 (2 parameters) <= used with on-fraction\n",
    "\n",
    "    * 1080: division (2 parameters)\n",
    "\n",
    "* Previous month\n",
    "    * 1121: monthly derivative of previous month (1 parameter)\n",
    "    * 1122: yearly derivative of previous month (1 parameter)\n",
    "\n",
    "* Grid properties(?)\n",
    "    * 1130: A*grid height (1 parameter)\n",
    "    * 1140: A/(B*C) ? (3 parameters)\n",
    "    * 1160: A*B (2 parameters)\n",
    "    * 1200: ternary (2 parameters)\n",
    "    * 1210: sum over layers (1 parameter)\n",
    "\n",
    "* Per sector\n",
    "    * 1110: ??? (1 parameter) <= per sector\n",
    "    * 1245: ??? (1 parameter) <= per sector\n",
    "    * 1246: derivative of 1245 (1 parameter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_from_dimensionality(dimensionality_string):\n",
    "    if dimensionality_string == '':\n",
    "        return ''\n",
    "    unit = ''\n",
    "    if dimensionality_string[0] == '-':\n",
    "        unit = '1'\n",
    "    d = ''\n",
    "    for c in dimensionality_string:\n",
    "        if c == '|':\n",
    "            unit = unit + unit_list[int(d)]['current']\n",
    "            d = ''\n",
    "        elif c == '-':\n",
    "            unit = unit + '/'\n",
    "        else:\n",
    "            d = d + c\n",
    "    return unit\n",
    "\n",
    "def unit_from_property(property_):\n",
    "    return unit_from_dimensionality(property_list[property_]['dimensionality_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/WELLS/Origins']\n",
    "well_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/WellTable']\n",
    "well_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Variables']\n",
    "well_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "well_property_list = replace_components_property_list(well_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Timesteps']\n",
    "well_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "well_day_list = [day_list[ts] for ts in well_timestep_list.values()]\n",
    "well_date_list = [date_list[ts] for ts in well_timestep_list.values()]\n",
    "\n",
    "def get_well_property(property_name, well_name):\n",
    "    dataset = f['TimeSeries/WELLS/Data']\n",
    "    return dataset[:,well_property_list[property_name],well_list[well_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/GROUPS/Origins']\n",
    "group_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/GroupTable']\n",
    "group_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Variables']\n",
    "group_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "group_property_list = replace_components_property_list(group_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Timesteps']\n",
    "group_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "group_day_list = [day_list[ts] for ts in group_timestep_list.values()]\n",
    "group_date_list = [date_list[ts] for ts in group_timestep_list.values()]\n",
    "\n",
    "def get_group_property(property_name, group_name):\n",
    "    dataset = f['TimeSeries/GROUPS/Data']\n",
    "    return dataset[:,group_property_list[property_name],group_list[group_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/LAYERS/Origins']\n",
    "layer_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_parent = {f'{parent.decode()}{{{name.decode()}}}':parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_connection = {f'{parent.decode()}{{{name.decode()}}}':connection for (name,parent,connection) in zip(dataset['Name'], dataset['Parent'], dataset['Connect To'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Variables']\n",
    "layer_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "layer_property_list = replace_components_property_list(layer_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Timesteps']\n",
    "layer_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "layer_day_list = [day_list[ts] for ts in layer_timestep_list.values()]\n",
    "layer_date_list = [date_list[ts] for ts in layer_timestep_list.values()]\n",
    "\n",
    "def get_layer_property(property_name, layer_name):\n",
    "    dataset = f['TimeSeries/LAYERS/Data']\n",
    "    return dataset[:,layer_property_list[property_name],layer_list[layer_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SECTORS/Origins']\n",
    "sector_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Variables']\n",
    "sector_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "sector_property_list = replace_components_property_list(sector_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Timesteps']\n",
    "sector_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "sector_day_list = [day_list[ts] for ts in sector_timestep_list.values()]\n",
    "sector_date_list = [date_list[ts] for ts in sector_timestep_list.values()]\n",
    "\n",
    "def get_sector_property(property_name, sector_name):\n",
    "    dataset = f['TimeSeries/SECTORS/Data']\n",
    "    return dataset[:,sector_property_list[property_name],sector_list[sector_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SPECIAL HISTORY/Variables']\n",
    "special_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "dataset = f['TimeSeries/SPECIAL HISTORY/Timesteps']\n",
    "special_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "special_property_list = replace_components_property_list(special_property_list)\n",
    "\n",
    "special_day_list = [day_list[ts] for ts in special_timestep_list.values()]\n",
    "special_date_list = [date_list[ts] for ts in special_timestep_list.values()]\n",
    "\n",
    "def get_special_property(property_name):\n",
    "    dataset = f['TimeSeries/SPECIAL HISTORY/Data']\n",
    "    return dataset[:,special_property_list[property_name],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties']\n",
    "grid_timestep_list = dict()\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/{key}\"]\n",
    "    if isinstance(sub_dataset, h5py._hl.group.Group):\n",
    "        grid_timestep_list[i] = key\n",
    "        i += 1\n",
    "    \n",
    "grid_day_list = [day_list[int(ts)] for ts in grid_timestep_list.values()]\n",
    "grid_date_list = [date_list[int(ts)] for ts in grid_timestep_list.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47x39x291 = 533403 cells\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "ni = dataset['IGNTID'][0]\n",
    "nj = dataset['IGNTJD'][0]\n",
    "nk = dataset['IGNTKD'][0]\n",
    "\n",
    "print(f'{ni}x{nj}x{nk} = {ni*nj*nk} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties/Statistics']\n",
    "grid_property_list = {name.decode().replace('/','%2F'):{'min':min_, 'max':max_, 'timesteps':set()} for name,min_,max_ in zip(dataset['Keyword'],dataset['Min'],dataset['Max'])}\n",
    "\n",
    "def _list_grid_properties(timestep, add_timestep=True):\n",
    "    dataset = f[f'SpatialProperties/{timestep}']\n",
    "    for key in dataset.keys():\n",
    "        sub_dataset = f[f\"SpatialProperties/{timestep}/{key}\"]\n",
    "        if isinstance(sub_dataset, h5py._hl.dataset.Dataset):\n",
    "            if key in grid_property_list:\n",
    "                grid_property_list[key]['size'] = sub_dataset.size\n",
    "                if add_timestep:\n",
    "                    grid_property_list[key]['timesteps'].add(timestep)\n",
    "            else:\n",
    "                raise ValueError(f'{key} not listed previously!')\n",
    "\n",
    "_list_grid_properties('000000/GRID', False)\n",
    "for ts in grid_timestep_list.values():\n",
    "    _list_grid_properties(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BLOCKDEPTH: 533,403 -> Grid block depths for all layers\n",
      "  BLOCKPVOL: 67,241 -> Block pore volume\n",
      "  BLOCKS: 4,267,224 -> Grid Block connectivity of Node Based Corner Point Grid\n",
      "  BLOCKSIZE: 1,600,209 -> Grid block sizes in three directions\n",
      "  BVOL: 67,241 -> Gross Block Volume = dx*dy*dz\n",
      "  ICNTDR: 176,572 -> Connection direction\n",
      "  ICSTBC: 533,403 -> Complete storage to block type\n",
      "  ICSTCG: 533,403 -> Complete storage to child grid\n",
      "  ICSTGN: 533,403 -> Complete storage to grid number\n",
      "  ICSTPB: 533,403 -> Complete storage to parent block\n",
      "  ICSTPS: 533,403 -> Complete storage to packed storage\n",
      "  ICTPS1: 176,572 -> Connection to lower packed storage\n",
      "  ICTPS2: 176,572 -> Connection to upper packed storage\n",
      "  IGNTFR: 1 -> Grid number to first fracture CS index\n",
      "  IGNTGT: 1 -> Grid number to grid type\n",
      "  IGNTID: 1 -> Grid number to no. of I direction blocks\n",
      "  IGNTJD: 1 -> Grid number to no. of J direction blocks\n",
      "  IGNTKD: 1 -> Grid number to no. of K direction blocks\n",
      "  IGNTNC: 2 -> Grid number to last block CS index\n",
      "  IGNTNS: 2 -> Grid number to last block SS index\n",
      "  IGNTZA: 1 -> Grid number to local Z direction\n",
      "  IPSTAC: 67,241 -> Packed storage to active status\n",
      "  IPSTBT: 67,241 -> Packed storage to block type\n",
      "  IPSTCS: 67,241 -> Packed storage to complete storage\n",
      "  ISECTGEOM: 67,242 -> Sector geometry array\n",
      "  NODES: 1,886,853 -> Grid Nodes' Coordinates, Node Based Corner Point Grid\n",
      "  WELLRADIUS: 1 -> Radius of wellbore in centre of grid\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/000000/GRID/{key}\"]\n",
    "    size = '{:,}'.format(sub_dataset.size)\n",
    "    print(f'  {key}: {size} -> {property_list[key][\"long name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICSTBC': {'min': -2.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTCG': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTGN': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPS': {'min': 0.0, 'max': 67241.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPB': {'min': 1.0, 'max': 533403.0, 'timesteps': set(), 'size': 533403},\n",
       " 'IPSTCS': {'min': 373.0, 'max': 533075.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTBT': {'min': 9.0, 'max': 9.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTAC': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IGNTID': {'min': 47.0, 'max': 47.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTJD': {'min': 39.0, 'max': 39.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTKD': {'min': 291.0, 'max': 291.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTZA': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTGT': {'min': 12.0, 'max': 12.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTFR': {'min': 533404.0, 'max': 533404.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTNC': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'IGNTNS': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'ICTPS1': {'min': 1.0, 'max': 67238.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICTPS2': {'min': 3.0, 'max': 67240.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICNTDR': {'min': 1.0, 'max': 3.0, 'timesteps': set(), 'size': 176572},\n",
       " 'BLOCKSIZE': {'min': 0.0,\n",
       "  'max': 277.3068,\n",
       "  'timesteps': set(),\n",
       "  'size': 1600209},\n",
       " 'BLOCKDEPTH': {'min': 5092.376,\n",
       "  'max': 5818.083,\n",
       "  'timesteps': set(),\n",
       "  'size': 533403},\n",
       " 'NODES': {'min': 5081.534,\n",
       "  'max': 7282220.5,\n",
       "  'timesteps': set(),\n",
       "  'size': 1886853},\n",
       " 'BLOCKS': {'min': 1.0, 'max': 628951.0, 'timesteps': set(), 'size': 4267224},\n",
       " 'ISECTGEOM': {'min': -1.0,\n",
       "  'max': 533075.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 67242},\n",
       " 'BLOCKPVOL': {'min': 2000.1254,\n",
       "  'max': 92200.94,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'BVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'WELLRADIUS': {'min': -100000000.0,\n",
       "  'max': -100000000.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 1}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{p:grid_property_list[p] for p in grid_property_list if len(grid_property_list[p]['timesteps'])==0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "    \n",
    "def get_cel_number(i,j,k, can_be_iterable=True):\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        return [ii + ni*(jj-1 + (kk-1)*nj) for (ii,jj,kk) in zip(i,j,k)]\n",
    "    return i + ni*(j-1 + (k-1)*nj)\n",
    "    \n",
    "def get_nodes_index(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/BLOCKS']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        return [dataset[(c-1)*8:c*8] for c in i]\n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return dataset[(i-1)*8:i*8]\n",
    "\n",
    "def get_cell_coordinates(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/NODES']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        nodes = get_nodes_index(i)\n",
    "        return [[dataset[(n-1)*3:n*3] for n in c] for c in nodes]\n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return [dataset[(n-1)*3:n*3] for n in get_nodes_index(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cel_number(44,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[373, 374]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cel_number([44, 45],[8, 8],[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   380,    381, 560722,    428,   2300,   2301, 560964,   2348])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nodes_index(44,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   380,    381, 560722,    428,   2300,   2301, 560964,   2348]),\n",
       " array([   381, 560718, 560723, 560722,   2301, 560960, 560965, 560964])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nodes_index([44, 45],[8, 8],[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   380,    381, 560722,    428,   2300,   2301, 560964,   2348])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nodes_index(373)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   380,    381, 560722,    428,   2300,   2301, 560964,   2348]),\n",
       " array([   381, 560718, 560723, 560722,   2301, 560960, 560965, 560964])]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nodes_index([373,374])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       " array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       " array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       " array([7.78305093e+05, 7.28067781e+06, 5.48975540e+03]),\n",
       " array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       " array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       " array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       " array([7.78302914e+05, 7.28067793e+06, 5.49256980e+03])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cell_coordinates(44,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       " array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       " array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       " array([7.78305093e+05, 7.28067781e+06, 5.48975540e+03]),\n",
       " array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       " array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       " array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       " array([7.78302914e+05, 7.28067793e+06, 5.49256980e+03])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cell_coordinates(373)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78305093e+05, 7.28067781e+06, 5.48975540e+03]),\n",
       "  array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78302914e+05, 7.28067793e+06, 5.49256980e+03])],\n",
       " [array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.77866625e+05, 7.28093580e+06, 5.55959280e+03]),\n",
       "  array([7.77841306e+05, 7.28073571e+06, 5.56067090e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.77866625e+05, 7.28093580e+06, 5.55959280e+03]),\n",
       "  array([7.77841306e+05, 7.28073571e+06, 5.56067090e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03])],\n",
       " [array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03]),\n",
       "  array([7.76189193e+05, 7.26352049e+06, 5.81808300e+03])],\n",
       " [array([7.80993402e+05, 7.27970809e+06, 5.41150000e+03]),\n",
       "  array([7.80801463e+05, 7.27973288e+06, 5.40333740e+03]),\n",
       "  array([7.80788080e+05, 7.27953338e+06, 5.36633590e+03]),\n",
       "  array([7.80978485e+05, 7.27950868e+06, 5.37400780e+03]),\n",
       "  array([7.80993402e+05, 7.27970809e+06, 5.41150000e+03]),\n",
       "  array([7.80801463e+05, 7.27973288e+06, 5.40333740e+03]),\n",
       "  array([7.80788080e+05, 7.27953338e+06, 5.36633590e+03]),\n",
       "  array([7.80978485e+05, 7.27950868e+06, 5.37400780e+03])]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cell_coordinates([373, 374, 250, 547])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78305093e+05, 7.28067781e+06, 5.48975540e+03]),\n",
       "  array([7.78326573e+05, 7.28087532e+06, 5.49325880e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78302914e+05, 7.28067793e+06, 5.49256980e+03])],\n",
       " [array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.77866625e+05, 7.28093580e+06, 5.55959280e+03]),\n",
       "  array([7.77841306e+05, 7.28073571e+06, 5.56067090e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03]),\n",
       "  array([7.78103477e+05, 7.28090551e+06, 5.52160110e+03]),\n",
       "  array([7.77866625e+05, 7.28093580e+06, 5.55959280e+03]),\n",
       "  array([7.77841306e+05, 7.28073571e+06, 5.56067090e+03]),\n",
       "  array([7.78075410e+05, 7.28070802e+06, 5.52315280e+03])]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cell_coordinates([44, 45],[8, 8],[1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
