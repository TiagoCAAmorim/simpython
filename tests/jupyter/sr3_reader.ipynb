{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR3 Reader\n",
    "\n",
    "* Reads data from SR3 file (HDF).\n",
    "* Return groups, wells, special and grid properties list.\n",
    "* Return 2D and 3D Time vector.\n",
    "* Return a 2D or 3D property.\n",
    "* Save all data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Groups in the HDF file:\n",
      "  General\n",
      "  SpatialProperties\n",
      "  Tables\n",
      "  TimeSeries\n",
      "\n",
      "All Groups in the HDF file:\n",
      "   General\t<class 'h5py._hl.group.Group'>\n",
      "   General/ComponentTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/EventTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/HistoryTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/MasterTimeTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/NameRecordTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/TableAssociations\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitConversionTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitsTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/BKRGCL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRGRL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWIRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSLCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/GRID/BLOCKDEPTH\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKPVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKSIZE\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICNTDR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTBC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTGN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPB\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS1\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS2\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTFR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTGT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTID\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTJD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTKD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTZA\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTAC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTBT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTCS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ISECTGEOM\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/NODES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/WELLRADIUS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/KRSETN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/MODBVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/NET%2FGROSS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCGMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWSHF\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/POR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000009/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/Statistics\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000/GO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/GroupTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/LAYERS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/LayerTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SECTORS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SPECIAL HISTORY/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/WELLS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/OperatingMode\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/WellTable\t<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r') as file:\n",
    "    print(\"Main Groups in the HDF file:\")\n",
    "    for dataset in file.keys():\n",
    "        print(f'  {dataset}')\n",
    "\n",
    "    print(\"\\nAll Groups in the HDF file:\")\n",
    "    def get_type(name):\n",
    "        print(f'   {name:}\\t{type(file[name])}')\n",
    "    file.visit(get_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/MasterTimeTable']\n",
    "day_list = {number:days for (number,days) in zip(dataset['Index'], dataset['Offset in days'])}\n",
    "\n",
    "def parse_date(date):\n",
    "    date_string = str(date)\n",
    "    integer_part = int(date_string.split('.')[0])\n",
    "    decimal_part = float(\"0.\" + date_string.split('.')[1])\n",
    "\n",
    "    parsed_date = datetime.strptime(str(integer_part), \"%Y%m%d\")\n",
    "    fraction_of_day = timedelta(days=decimal_part)\n",
    "    return parsed_date + fraction_of_day\n",
    "\n",
    "dataset = f['General/MasterTimeTable']\n",
    "date_list = {number:parse_date(date) for (number,date) in zip(dataset['Index'], dataset['Date'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/UnitsTable']\n",
    "unit_list = {number:{'internal':in_name.decode(), 'current':out_name.decode(), 'conversion':dict()} for (number,in_name,out_name) in zip(dataset['Index'],dataset['Internal Unit'],dataset['Output Unit'])}\n",
    "\n",
    "dataset = f['General/UnitConversionTable']\n",
    "for (number, name, gain, offset) in zip(dataset['Dimensionality'],dataset['Unit Name'],dataset['Gain'],dataset['Offset']):\n",
    "    unit_list[number]['conversion'][name.decode()] = (1./gain, offset * (-1.))\n",
    "\n",
    "for d in unit_list.values():\n",
    "    if d['internal'] != d['current']:\n",
    "        gain, offset = d['conversion'][d['internal']]\n",
    "        for k in d['conversion']:\n",
    "            g, o = d['conversion'][k]\n",
    "            d['conversion'][k] = (g / gain, o - offset)\n",
    "\n",
    "def set_current_unit(dimensionality, unit):\n",
    "    if unit not in unit_list[dimensionality]['conversion']:\n",
    "        raise ValueError(f'{unit} is not a valid unit for the current dimension.')\n",
    "    unit_list[dimensionality]['current'] = unit\n",
    "\n",
    "def unit_conversion(value, dimensionality, unit=None):\n",
    "    if unit is None:\n",
    "        unit = unit_list[dimensionality]['current']\n",
    "    if unit == unit_list[dimensionality]['internal']:\n",
    "        return value\n",
    "    gain, offset = unit_list[dimensionality]['conversion'][unit]\n",
    "    if gain == 1. and offset == 0.:\n",
    "        return value\n",
    "    else:\n",
    "        return value * gain + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/ComponentTable']\n",
    "component_list = {(number+1):name[0].decode() for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "def replace_components_property_list(property_list):\n",
    "    pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    def replace(match):\n",
    "        number = int(match.group(1))\n",
    "        return f'({str(component_list.get(number, match.group(1)))})'\n",
    "    return {pattern.sub(replace, k):v for k,v in property_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/NameRecordTable']\n",
    "property_list = dict()\n",
    "for (keyword,name,long_name,dimensionality) in zip(dataset['Keyword'],dataset['Name'],dataset['Long Name'],dataset['Dimensionality']):\n",
    "    if keyword != '':\n",
    "        keyword = keyword.decode()\n",
    "        name = name.decode()\n",
    "        long_name = long_name.decode()\n",
    "        dimensionality = dimensionality.decode()\n",
    "        if keyword[-2:] == '$C':\n",
    "            for c in component_list.values():\n",
    "                property_list[f'{keyword[:-2]}({c})'] = {'name':name.replace('$C', f' ({c})'), 'long name':long_name.replace('$C', f' ({c})'), 'dimensionality_string':dimensionality}\n",
    "        else:\n",
    "            property_list[keyword] = {'name':name, 'long name':long_name, 'dimensionality_string':dimensionality}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Formulas\n",
    "* Basic\n",
    "    * 1035: sum (2 parameters)\n",
    "    * 1037: sum (3 parameters)\n",
    "\n",
    "* Time derivatives\n",
    "    * 1040: derivative (1 parameter)\n",
    "    * 1045: monthly derivative (1 parameter)\n",
    "    * 1046: quarterly derivative (1 parameter)\n",
    "    * 1047: yearly derivative (1 parameter)\n",
    "    * 1048: daily derivative (1 parameter)\n",
    "    * 1049: weekly derivative (1 parameter)\n",
    "\n",
    "* Percentage\n",
    "    * 1055: A*100 (1 parameter)\n",
    "\n",
    "* Division\n",
    "    * 1060: division (2 parameters)\n",
    "    * 1062: division * 100 (2 parameters) <= used with on-fraction\n",
    "\n",
    "    * 1080: division (2 parameters)\n",
    "\n",
    "* Previous month\n",
    "    * 1121: monthly derivative of previous month (1 parameter)\n",
    "    * 1122: yearly derivative of previous month (1 parameter)\n",
    "\n",
    "* Grid properties(?)\n",
    "    * 1130: A*grid height (1 parameter)\n",
    "    * 1140: A/(B*C) ? (3 parameters)\n",
    "    * 1160: A*B (2 parameters)\n",
    "    * 1200: ternary (2 parameters)\n",
    "    * 1210: sum over layers (1 parameter)\n",
    "\n",
    "* Per sector\n",
    "    * 1110: ??? (1 parameter) <= per sector\n",
    "    * 1245: ??? (1 parameter) <= per sector\n",
    "    * 1246: derivative of 1245 (1 parameter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_from_dimensionality(dimensionality_string):\n",
    "    if dimensionality_string == '':\n",
    "        return ''\n",
    "    unit = ''\n",
    "    if dimensionality_string[0] == '-':\n",
    "        unit = '1'\n",
    "    d = ''\n",
    "    for c in dimensionality_string:\n",
    "        if c == '|':\n",
    "            unit = unit + unit_list[int(d)]['current']\n",
    "            d = ''\n",
    "        elif c == '-':\n",
    "            unit = unit + '/'\n",
    "        else:\n",
    "            d = d + c\n",
    "    return unit\n",
    "\n",
    "def unit_from_property(property_):\n",
    "    return unit_from_dimensionality(property_list[property_]['dimensionality_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/WELLS/Origins']\n",
    "well_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/WellTable']\n",
    "well_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Variables']\n",
    "well_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "well_property_list = replace_components_property_list(well_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Timesteps']\n",
    "well_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "well_day_list = [day_list[ts] for ts in well_timestep_list.values()]\n",
    "well_date_list = [date_list[ts] for ts in well_timestep_list.values()]\n",
    "\n",
    "def get_well_property(property_name, well_name):\n",
    "    dataset = f['TimeSeries/WELLS/Data']\n",
    "    return dataset[:,well_property_list[property_name],well_list[well_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/GROUPS/Origins']\n",
    "group_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/GroupTable']\n",
    "group_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Variables']\n",
    "group_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "group_property_list = replace_components_property_list(group_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Timesteps']\n",
    "group_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "group_day_list = [day_list[ts] for ts in group_timestep_list.values()]\n",
    "group_date_list = [date_list[ts] for ts in group_timestep_list.values()]\n",
    "\n",
    "def get_group_property(property_name, group_name):\n",
    "    dataset = f['TimeSeries/GROUPS/Data']\n",
    "    return dataset[:,group_property_list[property_name],group_list[group_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/LAYERS/Origins']\n",
    "layer_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_parent = {f'{parent.decode()}{{{name.decode()}}}':parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_connection = {f'{parent.decode()}{{{name.decode()}}}':connection for (name,parent,connection) in zip(dataset['Name'], dataset['Parent'], dataset['Connect To'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Variables']\n",
    "layer_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "layer_property_list = replace_components_property_list(layer_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Timesteps']\n",
    "layer_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "layer_day_list = [day_list[ts] for ts in layer_timestep_list.values()]\n",
    "layer_date_list = [date_list[ts] for ts in layer_timestep_list.values()]\n",
    "\n",
    "def get_layer_property(property_name, layer_name):\n",
    "    dataset = f['TimeSeries/LAYERS/Data']\n",
    "    return dataset[:,layer_property_list[property_name],layer_list[layer_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SECTORS/Origins']\n",
    "sector_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Variables']\n",
    "sector_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "sector_property_list = replace_components_property_list(sector_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Timesteps']\n",
    "sector_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "sector_day_list = [day_list[ts] for ts in sector_timestep_list.values()]\n",
    "sector_date_list = [date_list[ts] for ts in sector_timestep_list.values()]\n",
    "\n",
    "def get_sector_property(property_name, sector_name):\n",
    "    dataset = f['TimeSeries/SECTORS/Data']\n",
    "    return dataset[:,sector_property_list[property_name],sector_list[sector_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SPECIAL HISTORY/Variables']\n",
    "special_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "dataset = f['TimeSeries/SPECIAL HISTORY/Timesteps']\n",
    "special_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "special_property_list = replace_components_property_list(special_property_list)\n",
    "\n",
    "special_day_list = [day_list[ts] for ts in special_timestep_list.values()]\n",
    "special_date_list = [date_list[ts] for ts in special_timestep_list.values()]\n",
    "\n",
    "def get_special_property(property_name):\n",
    "    dataset = f['TimeSeries/SPECIAL HISTORY/Data']\n",
    "    return dataset[:,special_property_list[property_name],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties']\n",
    "grid_timestep_list = dict()\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/{key}\"]\n",
    "    if isinstance(sub_dataset, h5py._hl.group.Group):\n",
    "        grid_timestep_list[i] = key\n",
    "        i += 1\n",
    "    \n",
    "grid_day_list = [day_list[int(ts)] for ts in grid_timestep_list.values()]\n",
    "grid_date_list = [date_list[int(ts)] for ts in grid_timestep_list.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47x39x291 = 533403 cells\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "ni = dataset['IGNTID'][0]\n",
    "nj = dataset['IGNTJD'][0]\n",
    "nk = dataset['IGNTKD'][0]\n",
    "\n",
    "n_cells = ni*nj*nk\n",
    "print(f'{ni}x{nj}x{nk} = {n_cells} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties/Statistics']\n",
    "grid_property_list = {name.decode().replace('/','%2F'):{'min':min_, 'max':max_, 'timesteps':set()} for name,min_,max_ in zip(dataset['Keyword'],dataset['Min'],dataset['Max'])}\n",
    "\n",
    "def _list_grid_properties(timestep, add_timestep=True):\n",
    "    dataset = f[f'SpatialProperties/{timestep}']\n",
    "    for key in dataset.keys():\n",
    "        sub_dataset = f[f\"SpatialProperties/{timestep}/{key}\"]\n",
    "        if isinstance(sub_dataset, h5py._hl.dataset.Dataset):\n",
    "            if key in grid_property_list:\n",
    "                if 'size' in grid_property_list[key]:\n",
    "                    if grid_property_list[key]['size'] != sub_dataset.size:\n",
    "                        raise ValueError(f'Inconsistent grid size for {key}.')\n",
    "                else:\n",
    "                    grid_property_list[key]['size'] = sub_dataset.size\n",
    "                if add_timestep:\n",
    "                    grid_property_list[key]['timesteps'].add(timestep)\n",
    "            else:\n",
    "                raise ValueError(f'{key} not listed previously!')\n",
    "\n",
    "_list_grid_properties('000000/GRID', False)\n",
    "for ts in grid_timestep_list.values():\n",
    "    _list_grid_properties(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active cells: 67241\n"
     ]
    }
   ],
   "source": [
    "n_active_cells = grid_property_list['IPSTCS']['size']\n",
    "print(f'Number of active cells: {n_active_cells}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786744.8332000001\n",
      "7281231.6992999995\n",
      "776189.1926\n",
      "5259.2539\n",
      "785783.4680000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7277323.4571\n",
      "5352.8584\n"
     ]
    }
   ],
   "source": [
    "for i in [3,4,234,434,1023,3400,5000]:\n",
    "    print(f['SpatialProperties/000000/GRID/NODES'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICSTBC': {'min': -2.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTCG': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTGN': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPS': {'min': 0.0, 'max': 67241.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPB': {'min': 1.0, 'max': 533403.0, 'timesteps': set(), 'size': 533403},\n",
       " 'IPSTCS': {'min': 373.0, 'max': 533075.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTBT': {'min': 9.0, 'max': 9.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTAC': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IGNTID': {'min': 47.0, 'max': 47.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTJD': {'min': 39.0, 'max': 39.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTKD': {'min': 291.0, 'max': 291.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTZA': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTGT': {'min': 12.0, 'max': 12.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTFR': {'min': 533404.0, 'max': 533404.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTNC': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'IGNTNS': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'ICTPS1': {'min': 1.0, 'max': 67238.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICTPS2': {'min': 3.0, 'max': 67240.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICNTDR': {'min': 1.0, 'max': 3.0, 'timesteps': set(), 'size': 176572},\n",
       " 'BLOCKSIZE': {'min': 0.0,\n",
       "  'max': 277.3068,\n",
       "  'timesteps': set(),\n",
       "  'size': 1600209},\n",
       " 'BLOCKDEPTH': {'min': 5092.376,\n",
       "  'max': 5818.083,\n",
       "  'timesteps': set(),\n",
       "  'size': 533403},\n",
       " 'NODES': {'min': 5081.534,\n",
       "  'max': 7282220.5,\n",
       "  'timesteps': set(),\n",
       "  'size': 1886853},\n",
       " 'BLOCKS': {'min': 1.0, 'max': 628951.0, 'timesteps': set(), 'size': 4267224},\n",
       " 'ISECTGEOM': {'min': -1.0,\n",
       "  'max': 533075.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 67242},\n",
       " 'BLOCKPVOL': {'min': 2000.1254,\n",
       "  'max': 92200.94,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'BVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'WELLRADIUS': {'min': -100000000.0,\n",
       "  'max': -100000000.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 1},\n",
       " 'PERMI': {'min': 1e-19, 'max': 9.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PERMJ': {'min': 1e-19, 'max': 9.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PERMK': {'min': 1e-19, 'max': 0.9, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMI': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMJ': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMK': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLI': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLJ': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLK': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSWCRIT': {'min': 0.18, 'max': 0.18, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSGCRIT': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSORW': {'min': 0.35, 'max': 0.42, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSORG': {'min': 0.35, 'max': 0.44, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSWCON': {'min': 0.18, 'max': 0.18, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSGCON': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSOIRW': {'min': 0.0, 'max': 0.4, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSOIRG': {'min': 0.35, 'max': 0.4, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSLCON': {'min': 0.53, 'max': 0.58, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRWIRO': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROCW': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRWRO': {'min': 0.27747,\n",
       "  'max': 1.0,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'BKROCRW': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCWMAX': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCWSHF': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRGCL': {'min': 0.2, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROGCG': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRGRL': {'min': 0.181, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROGCRG': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCGMAX': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'POR': {'min': 0.009423881,\n",
       "  'max': 0.46211544,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'NET%2FGROSS': {'min': 1.0,\n",
       "  'max': 1.0,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'MODBVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'KRSETN': {'min': 1.0, 'max': 4.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'SO': {'min': 0.0,\n",
       "  'max': 0.8200331,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'SG': {'min': 0.0,\n",
       "  'max': 0.00017061036,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'SW': {'min': 0.17996694,\n",
       "  'max': 0.999999,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'PRES': {'min': 60578.65,\n",
       "  'max': 65599.945,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISO': {'min': 0.0,\n",
       "  'max': 0.39266887,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISG': {'min': 0.0,\n",
       "  'max': 0.06498869,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISW': {'min': 0.35,\n",
       "  'max': 0.35,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'Z(1)': {'min': 0.3731602,\n",
       "  'max': 0.44234335,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_property_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BLOCKDEPTH: 533,403 -> Grid block depths for all layers\n",
      "  BLOCKPVOL: 67,241 -> Block pore volume\n",
      "  BLOCKS: 4,267,224 -> Grid Block connectivity of Node Based Corner Point Grid\n",
      "  BLOCKSIZE: 1,600,209 -> Grid block sizes in three directions\n",
      "  BVOL: 67,241 -> Gross Block Volume = dx*dy*dz\n",
      "  ICNTDR: 176,572 -> Connection direction\n",
      "  ICSTBC: 533,403 -> Complete storage to block type\n",
      "  ICSTCG: 533,403 -> Complete storage to child grid\n",
      "  ICSTGN: 533,403 -> Complete storage to grid number\n",
      "  ICSTPB: 533,403 -> Complete storage to parent block\n",
      "  ICSTPS: 533,403 -> Complete storage to packed storage\n",
      "  ICTPS1: 176,572 -> Connection to lower packed storage\n",
      "  ICTPS2: 176,572 -> Connection to upper packed storage\n",
      "  IGNTFR: 1 -> Grid number to first fracture CS index\n",
      "  IGNTGT: 1 -> Grid number to grid type\n",
      "  IGNTID: 1 -> Grid number to no. of I direction blocks\n",
      "  IGNTJD: 1 -> Grid number to no. of J direction blocks\n",
      "  IGNTKD: 1 -> Grid number to no. of K direction blocks\n",
      "  IGNTNC: 2 -> Grid number to last block CS index\n",
      "  IGNTNS: 2 -> Grid number to last block SS index\n",
      "  IGNTZA: 1 -> Grid number to local Z direction\n",
      "  IPSTAC: 67,241 -> Packed storage to active status\n",
      "  IPSTBT: 67,241 -> Packed storage to block type\n",
      "  IPSTCS: 67,241 -> Packed storage to complete storage\n",
      "  ISECTGEOM: 67,242 -> Sector geometry array\n",
      "  NODES: 1,886,853 -> Grid Nodes' Coordinates, Node Based Corner Point Grid\n",
      "  WELLRADIUS: 1 -> Radius of wellbore in centre of grid\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/000000/GRID/{key}\"]\n",
    "    size = '{:,}'.format(sub_dataset.size)\n",
    "    print(f'  {key}: {size} -> {property_list[key][\"long name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICSTBC': {'min': -2.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTCG': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTGN': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPS': {'min': 0.0, 'max': 67241.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPB': {'min': 1.0, 'max': 533403.0, 'timesteps': set(), 'size': 533403},\n",
       " 'IPSTCS': {'min': 373.0, 'max': 533075.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTBT': {'min': 9.0, 'max': 9.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTAC': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IGNTID': {'min': 47.0, 'max': 47.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTJD': {'min': 39.0, 'max': 39.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTKD': {'min': 291.0, 'max': 291.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTZA': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTGT': {'min': 12.0, 'max': 12.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTFR': {'min': 533404.0, 'max': 533404.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTNC': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'IGNTNS': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'ICTPS1': {'min': 1.0, 'max': 67238.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICTPS2': {'min': 3.0, 'max': 67240.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICNTDR': {'min': 1.0, 'max': 3.0, 'timesteps': set(), 'size': 176572},\n",
       " 'BLOCKSIZE': {'min': 0.0,\n",
       "  'max': 277.3068,\n",
       "  'timesteps': set(),\n",
       "  'size': 1600209},\n",
       " 'BLOCKDEPTH': {'min': 5092.376,\n",
       "  'max': 5818.083,\n",
       "  'timesteps': set(),\n",
       "  'size': 533403},\n",
       " 'NODES': {'min': 5081.534,\n",
       "  'max': 7282220.5,\n",
       "  'timesteps': set(),\n",
       "  'size': 1886853},\n",
       " 'BLOCKS': {'min': 1.0, 'max': 628951.0, 'timesteps': set(), 'size': 4267224},\n",
       " 'ISECTGEOM': {'min': -1.0,\n",
       "  'max': 533075.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 67242},\n",
       " 'BLOCKPVOL': {'min': 2000.1254,\n",
       "  'max': 92200.94,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'BVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'WELLRADIUS': {'min': -100000000.0,\n",
       "  'max': -100000000.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 1}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{p:grid_property_list[p] for p in grid_property_list if len(grid_property_list[p]['timesteps'])==0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5, 6, 7, 8]), array([9, 0, 1, 2, 3, 4, 5])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split([1,2,3,4,5,6,7,8,9,0,1,2,3,4,5], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:01.309982\n"
     ]
    }
   ],
   "source": [
    "_CHUNK_SIZE = 1200\n",
    "\n",
    "def expand_list(original_list, items=1):\n",
    "    expanded_list = []\n",
    "    for value in original_list:\n",
    "        value_shift = (value-1)*items\n",
    "        expanded_list.append(value_shift)\n",
    "        for new_value in range(value_shift + 1, value_shift + items):\n",
    "            expanded_list.append(new_value)\n",
    "    return expanded_list\n",
    "\n",
    "def get_dataset_data(dataset, values_list):\n",
    "    if not is_iterable(values_list):\n",
    "        return dataset[values_list]\n",
    "    x_ordered = list(set(values_list)).copy()\n",
    "    x_ordered.sort()\n",
    "    sub_x_ordered = np.array_split(x_ordered, int(len(x_ordered)/_CHUNK_SIZE)+1)\n",
    "    y_dict = dict()\n",
    "    for x in sub_x_ordered:\n",
    "        y = dataset[x]\n",
    "        for x,y in zip(x, y):\n",
    "            y_dict[x] = y        \n",
    "    return  np.array([y_dict[x] for x in values_list])\n",
    "\n",
    "def is_iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "    \n",
    "def get_cel_number(i,j,k, can_be_iterable=True):\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        return [ii + ni*(jj-1 + (kk-1)*nj) for (ii,jj,kk) in zip(i,j,k)]\n",
    "    return i + ni*(j-1 + (k-1)*nj)\n",
    "\n",
    "def get_nodes_index(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/BLOCKS']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        y = get_dataset_data(dataset, expand_list(i, 8))\n",
    "        return np.reshape(y, (-1, 8))      \n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return dataset[(i-1)*8:i*8]\n",
    "\n",
    "def get_cell_coordinates(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/NODES']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        nodes = get_nodes_index(i)\n",
    "        y = get_dataset_data(dataset, expand_list(nodes.flatten(), 3))\n",
    "        return y.reshape((len(i), 8, 3))\n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return [dataset[(n-1)*3:n*3] for n in get_nodes_index(i)]\n",
    "\n",
    "\n",
    "size = 500\n",
    "i_list = list(np.random.randint(low=1, high=ni, size=size))\n",
    "j_list = list(np.random.randint(low=1, high=nj, size=size))\n",
    "k_list = list(np.random.randint(low=1, high=nk, size=size))\n",
    "\n",
    "cells = get_cel_number(i_list,j_list,k_list)\n",
    "\n",
    "start_time = datetime.now()\n",
    "x = get_cell_coordinates(cells)\n",
    "end_time = datetime.now()\n",
    "print(f'Elapsed time: {end_time - start_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(func, size):\n",
    "    i_list = list(np.random.randint(low=1, high=ni, size=size))\n",
    "    j_list = list(np.random.randint(low=1, high=nj, size=size))\n",
    "    k_list = list(np.random.randint(low=1, high=nk, size=size))\n",
    "    cells = get_cel_number(i_list,j_list,k_list)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    x = func(cells)\n",
    "    end_time = datetime.now()\n",
    "    # print(f'{s} elemts: {end_time - start_time} ({(end_time - start_time)/s*1000} per 1000 elemts)')\n",
    "    return (end_time - start_time)/size*1000 \n",
    "\n",
    "def time_function_sens(func, arguments_sizes):\n",
    "    t = []\n",
    "    for s in arguments_sizes:\n",
    "        t.append(time_function(func, s))\n",
    "    return t\n",
    "\n",
    "def time_function_opt(func, min_val, max_val, fmin_val=None, fmax_val=None):\n",
    "    if fmin_val is None:\n",
    "        fmin_val = time_function(func, min_val)\n",
    "        print(f'{min_val} => {fmin_val}')\n",
    "    if fmax_val is None:\n",
    "        fmax_val = time_function(func, max_val)\n",
    "        print(f'{max_val} => {fmax_val}')\n",
    "    a_val = int((2*min_val + max_val)/3)\n",
    "    b_val = int((min_val + 2*max_val)/3)\n",
    "    if a_val == min_val or b_val == max_val:\n",
    "        if fmin_val < fmax_val:\n",
    "            return min_val\n",
    "        else:\n",
    "            return max_val\n",
    "    fa_val = time_function(func, a_val)\n",
    "    fb_val = time_function(func, b_val)\n",
    "    print(f'{a_val} => {fa_val}')\n",
    "    print(f'{b_val} => {fb_val}')\n",
    "    if fa_val < fb_val:\n",
    "        return time_function_opt(func, min_val, b_val, fmin_val, fb_val)\n",
    "    else:\n",
    "        return time_function_opt(func, a_val, max_val, fa_val, fmax_val)\n",
    "\n",
    "\n",
    "# t = time_function_sens(get_nodes_index, [100, 200, 500, 1000, 2000, 5000])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
