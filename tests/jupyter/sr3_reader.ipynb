{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR3 Reader\n",
    "\n",
    "* Reads data from SR3 file (HDF).\n",
    "* Return groups, wells, special and grid properties list.\n",
    "* Return 2D and 3D Time vector.\n",
    "* Return a 2D or 3D property.\n",
    "* Save all data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Groups in the HDF file:\n",
      "  General\n",
      "  SpatialProperties\n",
      "  Tables\n",
      "  TimeSeries\n",
      "\n",
      "All Groups in the HDF file:\n",
      "   General\t<class 'h5py._hl.group.Group'>\n",
      "   General/ComponentTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/EventTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/HistoryTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/MasterTimeTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/NameRecordTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/TableAssociations\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitConversionTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   General/UnitsTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/BKRGCL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRGRL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROCW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKROGCRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWIRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BKRWRO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSGCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSLCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSOIRW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSORW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCON\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/BSWCRIT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000000/GRID/BLOCKDEPTH\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKPVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BLOCKSIZE\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/BVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICNTDR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTBC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTCG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTGN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPB\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICSTPS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS1\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ICTPS2\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTFR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTGT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTID\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTJD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTKD\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTNS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IGNTZA\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTAC\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTBT\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/IPSTCS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/ISECTGEOM\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/NODES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/GRID/WELLRADIUS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/KRSETN\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/MODBVOL\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/NET%2FGROSS\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCGMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWMAX\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PCWSHF\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PERMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/POR\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRLK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMI\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMJ\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/TRMK\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000000/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009\t<class 'h5py._hl.group.Group'>\n",
      "   SpatialProperties/000009/PRES\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/SW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISG\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISO\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/VISW\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/000009/Z(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   SpatialProperties/Statistics\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000\t<class 'h5py._hl.group.Group'>\n",
      "   Tables/000000/GO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/GO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(1)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(2)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(3)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   Tables/000000/WO-PERM-TABLE(4)\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/GROUPS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/GroupTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/GROUPS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/LAYERS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/LayerTable\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/LAYERS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SECTORS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SECTORS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/SPECIAL HISTORY/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/SPECIAL HISTORY/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS\t<class 'h5py._hl.group.Group'>\n",
      "   TimeSeries/WELLS/Data\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/OperatingMode\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Origins\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Status\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Timesteps\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/Variables\t<class 'h5py._hl.dataset.Dataset'>\n",
      "   TimeSeries/WELLS/WellTable\t<class 'h5py._hl.dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r') as file:\n",
    "    print(\"Main Groups in the HDF file:\")\n",
    "    for dataset in file.keys():\n",
    "        print(f'  {dataset}')\n",
    "\n",
    "    print(\"\\nAll Groups in the HDF file:\")\n",
    "    def get_type(name):\n",
    "        print(f'   {name:}\\t{type(file[name])}')\n",
    "    file.visit(get_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(r'..\\sr3\\base_case_3a.sr3', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/MasterTimeTable']\n",
    "day_list = {number:days for (number,days) in zip(dataset['Index'], dataset['Offset in days'])}\n",
    "\n",
    "def parse_date(date):\n",
    "    date_string = str(date)\n",
    "    integer_part = int(date_string.split('.')[0])\n",
    "    decimal_part = float(\"0.\" + date_string.split('.')[1])\n",
    "\n",
    "    parsed_date = datetime.strptime(str(integer_part), \"%Y%m%d\")\n",
    "    fraction_of_day = timedelta(days=decimal_part)\n",
    "    return parsed_date + fraction_of_day\n",
    "\n",
    "dataset = f['General/MasterTimeTable']\n",
    "date_list = {number:parse_date(date) for (number,date) in zip(dataset['Index'], dataset['Date'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/UnitsTable']\n",
    "unit_list = {number:{'internal':in_name.decode(), 'current':out_name.decode(), 'conversion':dict()} for (number,in_name,out_name) in zip(dataset['Index'],dataset['Internal Unit'],dataset['Output Unit'])}\n",
    "\n",
    "dataset = f['General/UnitConversionTable']\n",
    "for (number, name, gain, offset) in zip(dataset['Dimensionality'],dataset['Unit Name'],dataset['Gain'],dataset['Offset']):\n",
    "    unit_list[number]['conversion'][name.decode()] = (1./gain, offset * (-1.))\n",
    "\n",
    "for d in unit_list.values():\n",
    "    if d['internal'] != d['current']:\n",
    "        gain, offset = d['conversion'][d['internal']]\n",
    "        for k in d['conversion']:\n",
    "            g, o = d['conversion'][k]\n",
    "            d['conversion'][k] = (g / gain, o - offset)\n",
    "\n",
    "def set_current_unit(dimensionality, unit):\n",
    "    if unit not in unit_list[dimensionality]['conversion']:\n",
    "        raise ValueError(f'{unit} is not a valid unit for the current dimension.')\n",
    "    unit_list[dimensionality]['current'] = unit\n",
    "\n",
    "def unit_conversion(value, dimensionality, unit=None):\n",
    "    if unit is None:\n",
    "        unit = unit_list[dimensionality]['current']\n",
    "    if unit == unit_list[dimensionality]['internal']:\n",
    "        return value\n",
    "    gain, offset = unit_list[dimensionality]['conversion'][unit]\n",
    "    if gain == 1. and offset == 0.:\n",
    "        return value\n",
    "    else:\n",
    "        return value * gain + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/ComponentTable']\n",
    "component_list = {(number+1):name[0].decode() for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "def replace_components_property_list(property_list):\n",
    "    pattern = re.compile(r'\\((\\d+)\\)')\n",
    "    def replace(match):\n",
    "        number = int(match.group(1))\n",
    "        return f'({str(component_list.get(number, match.group(1)))})'\n",
    "    return {pattern.sub(replace, k):v for k,v in property_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['General/NameRecordTable']\n",
    "property_list = dict()\n",
    "for (keyword,name,long_name,dimensionality) in zip(dataset['Keyword'],dataset['Name'],dataset['Long Name'],dataset['Dimensionality']):\n",
    "    if keyword != '':\n",
    "        keyword = keyword.decode()\n",
    "        name = name.decode()\n",
    "        long_name = long_name.decode()\n",
    "        dimensionality = dimensionality.decode()\n",
    "        if keyword[-2:] == '$C':\n",
    "            for c in component_list.values():\n",
    "                property_list[f'{keyword[:-2]}({c})'] = {'name':name.replace('$C', f' ({c})'), 'long name':long_name.replace('$C', f' ({c})'), 'dimensionality_string':dimensionality}\n",
    "        else:\n",
    "            property_list[keyword] = {'name':name, 'long name':long_name, 'dimensionality_string':dimensionality}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_from_dimensionality(dimensionality_string):\n",
    "    if dimensionality_string == '':\n",
    "        return ''\n",
    "    unit = ''\n",
    "    if dimensionality_string[0] == '-':\n",
    "        unit = '1'\n",
    "    d = ''\n",
    "    for c in dimensionality_string:\n",
    "        if c == '|':\n",
    "            unit = unit + unit_list[int(d)]['current']\n",
    "            d = ''\n",
    "        elif c == '-':\n",
    "            unit = unit + '/'\n",
    "        else:\n",
    "            d = d + c\n",
    "    return unit\n",
    "\n",
    "def unit_from_property(property_):\n",
    "    return unit_from_dimensionality(property_list[property_]['dimensionality_string'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basic\n",
    "    * 1035: sum (2 parameters)\n",
    "    * 1037: sum (3 parameters)\n",
    "\n",
    "* Time derivatives\n",
    "    * 1040: derivative (1 parameter)\n",
    "    * 1045: monthly derivative (1 parameter)\n",
    "    * 1046: quarterly derivative (1 parameter)\n",
    "    * 1047: yearly derivative (1 parameter)\n",
    "    * 1048: daily derivative (1 parameter)\n",
    "    * 1049: weekly derivative (1 parameter)\n",
    "\n",
    "* Percentage\n",
    "    * 1055: A*100 (1 parameter)\n",
    "\n",
    "* Division\n",
    "    * 1060: division (2 parameters)\n",
    "    * 1062: division * 100 (2 parameters) <= used with on-fraction\n",
    "\n",
    "    * 1080: division (2 parameters)\n",
    "\n",
    "* Previous month\n",
    "    * 1121: monthly derivative of previous month (1 parameter)\n",
    "    * 1122: yearly derivative of previous month (1 parameter)\n",
    "\n",
    "* Grid properties(?)\n",
    "    * 1130: A*grid height (1 parameter)\n",
    "    * 1140: A/(B*C) ? (3 parameters)\n",
    "    * 1160: A*B (2 parameters)\n",
    "    * 1200: ternary (2 parameters)\n",
    "    * 1210: sum over layers (1 parameter)\n",
    "\n",
    "* Per sector\n",
    "    * 1110: ??? (1 parameter) <= per sector\n",
    "    * 1245: ??? (1 parameter) <= per sector\n",
    "    * 1246: derivative of 1245 (1 parameter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "_element = {'special':{'':0}}\n",
    "_parent = dict()\n",
    "_connection = dict()\n",
    "_property = dict()\n",
    "_timestep = dict()\n",
    "_day = dict()\n",
    "_date = dict()\n",
    "# _data = dict()\n",
    "\n",
    "def _return_dataset(element_type, dataset_string):\n",
    "    el_type_string = element_type.upper() + 'S'\n",
    "    if element_type == 'special':\n",
    "        el_type_string = el_type_string + ' HISTORY'\n",
    "    s = f'TimeSeries/{el_type_string}/{dataset_string}'\n",
    "    if s in f:\n",
    "        return f[s]\n",
    "    else:\n",
    "        raise ValueError(f'Dataset {dataset_string} not found for {element_type}.')\n",
    "    \n",
    "def get_elements(element_type):        \n",
    "    if element_type not in _element:\n",
    "        dataset = _return_dataset(element_type=element_type, dataset_string='Origins')\n",
    "        _element[element_type] = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "    return _element[element_type]\n",
    "\n",
    "def get_properties(element_type):\n",
    "    if element_type not in _property:\n",
    "        dataset = _return_dataset(element_type=element_type, dataset_string='Variables')\n",
    "        _property[element_type] = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "        _property[element_type] = replace_components_property_list(_property[element_type])\n",
    "    return _property[element_type]\n",
    "\n",
    "def get_timesteps(element_type):\n",
    "    if element_type not in _timestep:\n",
    "        dataset = _return_dataset(element_type=element_type, dataset_string='Timesteps')\n",
    "        _timestep[element_type] = dataset[:]\n",
    "    return _timestep[element_type]\n",
    "\n",
    "def get_days(element_type):\n",
    "    if element_type not in _day:\n",
    "        timesteps = get_timesteps(element_type=element_type)\n",
    "        _day[element_type] = np.vectorize(lambda x: day_list[x])(timesteps)\n",
    "    return _day[element_type]\n",
    "\n",
    "def get_dates(element_type):\n",
    "    if element_type not in _date:\n",
    "        timesteps = get_timesteps(element_type=element_type)\n",
    "        _date[element_type] = np.vectorize(lambda x: date_list[x])(timesteps)\n",
    "    return _date[element_type]\n",
    "\n",
    "def _get_parents(element_type):\n",
    "    if element_type in ['well', 'group', 'layer']:\n",
    "        dataset = _return_dataset(element_type=element_type, dataset_string=f'{element_type.capitalize()}Table')\n",
    "        def _name(name, parent):\n",
    "            if element_type == 'layer':\n",
    "                return f'{parent.decode()}{{{name.decode()}}}'\n",
    "            else:\n",
    "                return name.decode()\n",
    "        _parent[element_type] = {_name(name, parent):parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "    else:\n",
    "        _parent[element_type] = {name:'' for name in get_elements(element_type)}\n",
    "\n",
    "def get_parent(element_type, element_name):\n",
    "    if element_type not in _parent:\n",
    "        _get_parents(element_type)\n",
    "    return _parent[element_type][element_name]\n",
    "\n",
    "def _get_connections(element_type):\n",
    "    if element_type == 'layer':\n",
    "        dataset = _return_dataset(element_type=element_type, dataset_string=f'{element_type.capitalize()}Table')\n",
    "        def _name(name, parent):\n",
    "            return f'{parent.decode()}{{{name.decode()}}}'\n",
    "        _connection[element_type] = {_name(name, parent):connection for (name,parent,connection) in zip(dataset['Name'], dataset['Parent'], dataset['Connect To'])}\n",
    "    else:\n",
    "        _parent[element_type] = {name:'' for name in get_elements(element_type)}\n",
    "\n",
    "def get_connection(element_type, element_name):\n",
    "    if element_type not in _connection:\n",
    "        _get_connections(element_type)\n",
    "    return _connection[element_type][element_name]\n",
    "\n",
    "def _concatenate_arrays(arr1, arr2):\n",
    "    # common_dtype = np.result_type(arr1, arr2)\n",
    "    # arr1 = arr1.astype(common_dtype)\n",
    "    # arr2 = arr2.astype(common_dtype)\n",
    "\n",
    "    if arr1.ndim == 1:\n",
    "        arr1 = arr1.reshape(-1,1)\n",
    "    if arr2.ndim == 1:\n",
    "        arr2 = arr2.reshape(-1,1)\n",
    "\n",
    "    return np.hstack((arr1, arr2))\n",
    "\n",
    "def get_data(element_type, property_name, element_name='', with_dates=False, with_days=False, with_timesteps=False):\n",
    "    dataset = _return_dataset(element_type=element_type, dataset_string='Data')\n",
    "    data = dataset[:,get_properties(element_type)[property_name],get_elements(element_type)[element_name]]\n",
    "    if with_dates:\n",
    "        return _concatenate_arrays(get_dates(element_type=element_type), data)\n",
    "    elif with_days:\n",
    "        return _concatenate_arrays(get_days(element_type=element_type), data)\n",
    "    elif with_timesteps:\n",
    "        return _concatenate_arrays(get_timesteps(element_type=element_type), data)\n",
    "    else:\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(get_elements('well')['P11'])\n",
    "print(get_elements('well')['P12'])\n",
    "\n",
    "print(get_properties('well')['OILRATSC'])\n",
    "print(get_properties('well')['GASRATSC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = _return_dataset(element_type='well', dataset_string='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[:,[20,21],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[datetime.datetime(2018, 10, 2, 0, 0), 6246.5344882818345, 0.0],\n",
       "       [datetime.datetime(2018, 10, 31, 23, 45, 36), 6246.517578890559,\n",
       "        0.0],\n",
       "       [datetime.datetime(2018, 11, 1, 0, 0), 6394.106652683749, 0.0],\n",
       "       ...,\n",
       "       [datetime.datetime(2024, 8, 1, 23, 45, 36), 5083.7696492729665,\n",
       "        4759.4954772827605],\n",
       "       [datetime.datetime(2024, 8, 2, 0, 0), 6082.504288854868, 0.0],\n",
       "       [datetime.datetime(2024, 8, 3, 0, 0), 6078.931879073354, 0.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=concatenate_data(x2,a)\n",
    "z[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dataset[:,20,[0,2]]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 658 and the array at index 1 has size 1316",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconcatenate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m, in \u001b[0;36mconcatenate_data\u001b[1;34m(arr1, arr2)\u001b[0m\n\u001b[0;32m      4\u001b[0m arr1 \u001b[38;5;241m=\u001b[39m arr1\u001b[38;5;241m.\u001b[39mastype(common_dtype)\n\u001b[0;32m      5\u001b[0m arr2 \u001b[38;5;241m=\u001b[39m arr2\u001b[38;5;241m.\u001b[39mastype(common_dtype)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tiago.LENOVO-I7\\Unicamp\\PHD\\simpython\\.venv\\Lib\\site-packages\\numpy\\core\\shape_base.py:359\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 658 and the array at index 1 has size 1316"
     ]
    }
   ],
   "source": [
    "concatenate_data(x2,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6246.53448828,    0.        ],\n",
       "       [6246.51757889,    0.        ],\n",
       "       [6394.10665268,    0.        ],\n",
       "       ...,\n",
       "       [5083.76964927, 4759.49547728],\n",
       "       [6082.50428885,    0.        ],\n",
       "       [6078.93187907,    0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_days('well')\n",
    "x2 = get_dates('well')\n",
    "y = get_data('well','GASRATSC','P11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(658,)\n",
      "658\n",
      "<class 'numpy.ndarray'>\n",
      "(658,)\n",
      "658\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(len(x))\n",
    "\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691745.811279528"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = concatenate_data(x,y)\n",
    "z[0,1]\n",
    "# z[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = concatenate_data(x2,y)\n",
    "type(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691745.811279528"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00000000e+01, 2.69174581e+06])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.hstack((x.reshape(-1,1),y.reshape(-1,1)))\n",
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00000000e+01, 2.69174581e+06],\n",
       "       [5.99900000e+01, 2.69173852e+06],\n",
       "       [6.00000000e+01, 2.75533735e+06],\n",
       "       ...,\n",
       "       [2.16099000e+03, 2.19225966e+06],\n",
       "       [2.16100000e+03, 2.62282463e+06],\n",
       "       [2.16200000e+03, 2.62131320e+06]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 658)\n"
     ]
    }
   ],
   "source": [
    "z = np.vstack((x,y))\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[datetime.datetime(2018, 10, 2, 0, 0),\n",
       "        datetime.datetime(2018, 10, 31, 23, 45, 36),\n",
       "        datetime.datetime(2018, 11, 1, 0, 0), ...,\n",
       "        datetime.datetime(2024, 8, 1, 23, 45, 36),\n",
       "        datetime.datetime(2024, 8, 2, 0, 0),\n",
       "        datetime.datetime(2024, 8, 3, 0, 0)],\n",
       "       [2691745.811279528, 2691738.5248579876, 2755337.352646691, ...,\n",
       "        2192259.657024043, 2622824.6299249204, 2621313.202984272]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  30.        , 6246.53448828],\n",
       "       [  59.99      , 6246.51757889],\n",
       "       [  60.        , 6394.10665268],\n",
       "       ...,\n",
       "       [2160.99      , 5083.76964927],\n",
       "       [2161.        , 6082.50428885],\n",
       "       [2162.        , 6078.93187907]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data('well','OILRATSC','P11', with_days=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/WELLS/Origins']\n",
    "_element['well'] = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/WellTable']\n",
    "_parent['well'] = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Variables']\n",
    "_property['well'] = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "_property['well'] = replace_components_property_list(_property['well'])\n",
    "\n",
    "dataset = f['TimeSeries/WELLS/Timesteps']\n",
    "_timestep['well'] = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "_day['well'] = [day_list[ts] for ts in _timestep['well'].values()]\n",
    "_date['well'] = [date_list[ts] for ts in _timestep['well'].values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/GROUPS/Origins']\n",
    "group_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/GroupTable']\n",
    "group_parent = {name.decode():parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Variables']\n",
    "group_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "group_property_list = replace_components_property_list(group_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/GROUPS/Timesteps']\n",
    "group_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "group_day_list = [day_list[ts] for ts in group_timestep_list.values()]\n",
    "group_date_list = [date_list[ts] for ts in group_timestep_list.values()]\n",
    "\n",
    "def get_group_property(property_name, group_name):\n",
    "    dataset = f['TimeSeries/GROUPS/Data']\n",
    "    return dataset[:,group_property_list[property_name],group_list[group_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/LAYERS/Origins']\n",
    "layer_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_parent = {f'{parent.decode()}{{{name.decode()}}}':parent.decode() for (name,parent) in zip(dataset['Name'], dataset['Parent'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/LayerTable']\n",
    "layer_connection = {f'{parent.decode()}{{{name.decode()}}}':connection for (name,parent,connection) in zip(dataset['Name'], dataset['Parent'], dataset['Connect To'])}\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Variables']\n",
    "layer_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "layer_property_list = replace_components_property_list(layer_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/LAYERS/Timesteps']\n",
    "layer_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "layer_day_list = [day_list[ts] for ts in layer_timestep_list.values()]\n",
    "layer_date_list = [date_list[ts] for ts in layer_timestep_list.values()]\n",
    "\n",
    "def get_layer_property(property_name, layer_name):\n",
    "    dataset = f['TimeSeries/LAYERS/Data']\n",
    "    return dataset[:,layer_property_list[property_name],layer_list[layer_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SECTORS/Origins']\n",
    "sector_list = {name.decode():number for (number,name) in enumerate(dataset[:]) if name.decode()!=''}\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Variables']\n",
    "sector_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "sector_property_list = replace_components_property_list(sector_property_list)\n",
    "\n",
    "dataset = f['TimeSeries/SECTORS/Timesteps']\n",
    "sector_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "\n",
    "sector_day_list = [day_list[ts] for ts in sector_timestep_list.values()]\n",
    "sector_date_list = [date_list[ts] for ts in sector_timestep_list.values()]\n",
    "\n",
    "def get_sector_property(property_name, sector_name):\n",
    "    dataset = f['TimeSeries/SECTORS/Data']\n",
    "    return dataset[:,sector_property_list[property_name],sector_list[sector_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['TimeSeries/SPECIAL HISTORY/Variables']\n",
    "special_property_list = {name.decode():number for (number,name) in enumerate(dataset[:])}\n",
    "\n",
    "dataset = f['TimeSeries/SPECIAL HISTORY/Timesteps']\n",
    "special_timestep_list = {number:timestep for (number,timestep) in enumerate(dataset[:])}\n",
    "special_property_list = replace_components_property_list(special_property_list)\n",
    "\n",
    "special_day_list = [day_list[ts] for ts in special_timestep_list.values()]\n",
    "special_date_list = [date_list[ts] for ts in special_timestep_list.values()]\n",
    "\n",
    "def get_special_property(property_name):\n",
    "    dataset = f['TimeSeries/SPECIAL HISTORY/Data']\n",
    "    return dataset[:,special_property_list[property_name],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties']\n",
    "grid_timestep_list = dict()\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/{key}\"]\n",
    "    if isinstance(sub_dataset, h5py._hl.group.Group):\n",
    "        grid_timestep_list[i] = key\n",
    "        i += 1\n",
    "    \n",
    "grid_day_list = [day_list[int(ts)] for ts in grid_timestep_list.values()]\n",
    "grid_date_list = [date_list[int(ts)] for ts in grid_timestep_list.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47x39x291 = 533403 cells\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "ni = dataset['IGNTID'][0]\n",
    "nj = dataset['IGNTJD'][0]\n",
    "nk = dataset['IGNTKD'][0]\n",
    "\n",
    "n_cells = ni*nj*nk\n",
    "print(f'{ni}x{nj}x{nk} = {n_cells} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f['SpatialProperties/Statistics']\n",
    "grid_property_list = {name.decode().replace('/','%2F'):{'min':min_, 'max':max_, 'timesteps':set()} for name,min_,max_ in zip(dataset['Keyword'],dataset['Min'],dataset['Max'])}\n",
    "\n",
    "def _list_grid_properties(timestep, add_timestep=True):\n",
    "    dataset = f[f'SpatialProperties/{timestep}']\n",
    "    for key in dataset.keys():\n",
    "        sub_dataset = f[f\"SpatialProperties/{timestep}/{key}\"]\n",
    "        if isinstance(sub_dataset, h5py._hl.dataset.Dataset):\n",
    "            if key in grid_property_list:\n",
    "                if 'size' in grid_property_list[key]:\n",
    "                    if grid_property_list[key]['size'] != sub_dataset.size:\n",
    "                        raise ValueError(f'Inconsistent grid size for {key}.')\n",
    "                else:\n",
    "                    grid_property_list[key]['size'] = sub_dataset.size\n",
    "                if add_timestep:\n",
    "                    grid_property_list[key]['timesteps'].add(timestep)\n",
    "            else:\n",
    "                raise ValueError(f'{key} not listed previously!')\n",
    "\n",
    "_list_grid_properties('000000/GRID', False)\n",
    "for ts in grid_timestep_list.values():\n",
    "    _list_grid_properties(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active cells: 67241\n"
     ]
    }
   ],
   "source": [
    "n_active_cells = grid_property_list['IPSTCS']['size']\n",
    "print(f'Number of active cells: {n_active_cells}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786744.8332000001\n",
      "7281231.6992999995\n",
      "776189.1926\n",
      "5259.2539\n",
      "785783.4680000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7277323.4571\n",
      "5352.8584\n"
     ]
    }
   ],
   "source": [
    "for i in [3,4,234,434,1023,3400,5000]:\n",
    "    print(f['SpatialProperties/000000/GRID/NODES'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICSTBC': {'min': -2.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTCG': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTGN': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPS': {'min': 0.0, 'max': 67241.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPB': {'min': 1.0, 'max': 533403.0, 'timesteps': set(), 'size': 533403},\n",
       " 'IPSTCS': {'min': 373.0, 'max': 533075.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTBT': {'min': 9.0, 'max': 9.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTAC': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IGNTID': {'min': 47.0, 'max': 47.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTJD': {'min': 39.0, 'max': 39.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTKD': {'min': 291.0, 'max': 291.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTZA': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTGT': {'min': 12.0, 'max': 12.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTFR': {'min': 533404.0, 'max': 533404.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTNC': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'IGNTNS': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'ICTPS1': {'min': 1.0, 'max': 67238.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICTPS2': {'min': 3.0, 'max': 67240.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICNTDR': {'min': 1.0, 'max': 3.0, 'timesteps': set(), 'size': 176572},\n",
       " 'BLOCKSIZE': {'min': 0.0,\n",
       "  'max': 277.3068,\n",
       "  'timesteps': set(),\n",
       "  'size': 1600209},\n",
       " 'BLOCKDEPTH': {'min': 5092.376,\n",
       "  'max': 5818.083,\n",
       "  'timesteps': set(),\n",
       "  'size': 533403},\n",
       " 'NODES': {'min': 5081.534,\n",
       "  'max': 7282220.5,\n",
       "  'timesteps': set(),\n",
       "  'size': 1886853},\n",
       " 'BLOCKS': {'min': 1.0, 'max': 628951.0, 'timesteps': set(), 'size': 4267224},\n",
       " 'ISECTGEOM': {'min': -1.0,\n",
       "  'max': 533075.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 67242},\n",
       " 'BLOCKPVOL': {'min': 2000.1254,\n",
       "  'max': 92200.94,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'BVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'WELLRADIUS': {'min': -100000000.0,\n",
       "  'max': -100000000.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 1},\n",
       " 'PERMI': {'min': 1e-19, 'max': 9.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PERMJ': {'min': 1e-19, 'max': 9.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PERMK': {'min': 1e-19, 'max': 0.9, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMI': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMJ': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRMK': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLI': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLJ': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'TRLK': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSWCRIT': {'min': 0.18, 'max': 0.18, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSGCRIT': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSORW': {'min': 0.35, 'max': 0.42, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSORG': {'min': 0.35, 'max': 0.44, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSWCON': {'min': 0.18, 'max': 0.18, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSGCON': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSOIRW': {'min': 0.0, 'max': 0.4, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSOIRG': {'min': 0.35, 'max': 0.4, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BSLCON': {'min': 0.53, 'max': 0.58, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRWIRO': {'min': 1.0, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROCW': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRWRO': {'min': 0.27747,\n",
       "  'max': 1.0,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'BKROCRW': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCWMAX': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCWSHF': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRGCL': {'min': 0.2, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROGCG': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKRGRL': {'min': 0.181, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'BKROGCRG': {'min': 0.25, 'max': 1.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'PCGMAX': {'min': 0.0, 'max': 0.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'POR': {'min': 0.009423881,\n",
       "  'max': 0.46211544,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'NET%2FGROSS': {'min': 1.0,\n",
       "  'max': 1.0,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'MODBVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': {'000000'},\n",
       "  'size': 67241},\n",
       " 'KRSETN': {'min': 1.0, 'max': 4.0, 'timesteps': {'000000'}, 'size': 67241},\n",
       " 'SO': {'min': 0.0,\n",
       "  'max': 0.8200331,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'SG': {'min': 0.0,\n",
       "  'max': 0.00017061036,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'SW': {'min': 0.17996694,\n",
       "  'max': 0.999999,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'PRES': {'min': 60578.65,\n",
       "  'max': 65599.945,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISO': {'min': 0.0,\n",
       "  'max': 0.39266887,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISG': {'min': 0.0,\n",
       "  'max': 0.06498869,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'VISW': {'min': 0.35,\n",
       "  'max': 0.35,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241},\n",
       " 'Z(1)': {'min': 0.3731602,\n",
       "  'max': 0.44234335,\n",
       "  'timesteps': {'000000', '000009'},\n",
       "  'size': 67241}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_property_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BLOCKDEPTH: 533,403 -> Grid block depths for all layers\n",
      "  BLOCKPVOL: 67,241 -> Block pore volume\n",
      "  BLOCKS: 4,267,224 -> Grid Block connectivity of Node Based Corner Point Grid\n",
      "  BLOCKSIZE: 1,600,209 -> Grid block sizes in three directions\n",
      "  BVOL: 67,241 -> Gross Block Volume = dx*dy*dz\n",
      "  ICNTDR: 176,572 -> Connection direction\n",
      "  ICSTBC: 533,403 -> Complete storage to block type\n",
      "  ICSTCG: 533,403 -> Complete storage to child grid\n",
      "  ICSTGN: 533,403 -> Complete storage to grid number\n",
      "  ICSTPB: 533,403 -> Complete storage to parent block\n",
      "  ICSTPS: 533,403 -> Complete storage to packed storage\n",
      "  ICTPS1: 176,572 -> Connection to lower packed storage\n",
      "  ICTPS2: 176,572 -> Connection to upper packed storage\n",
      "  IGNTFR: 1 -> Grid number to first fracture CS index\n",
      "  IGNTGT: 1 -> Grid number to grid type\n",
      "  IGNTID: 1 -> Grid number to no. of I direction blocks\n",
      "  IGNTJD: 1 -> Grid number to no. of J direction blocks\n",
      "  IGNTKD: 1 -> Grid number to no. of K direction blocks\n",
      "  IGNTNC: 2 -> Grid number to last block CS index\n",
      "  IGNTNS: 2 -> Grid number to last block SS index\n",
      "  IGNTZA: 1 -> Grid number to local Z direction\n",
      "  IPSTAC: 67,241 -> Packed storage to active status\n",
      "  IPSTBT: 67,241 -> Packed storage to block type\n",
      "  IPSTCS: 67,241 -> Packed storage to complete storage\n",
      "  ISECTGEOM: 67,242 -> Sector geometry array\n",
      "  NODES: 1,886,853 -> Grid Nodes' Coordinates, Node Based Corner Point Grid\n",
      "  WELLRADIUS: 1 -> Radius of wellbore in centre of grid\n"
     ]
    }
   ],
   "source": [
    "dataset = f['SpatialProperties/000000/GRID']\n",
    "for key in dataset.keys():\n",
    "    sub_dataset = f[f\"SpatialProperties/000000/GRID/{key}\"]\n",
    "    size = '{:,}'.format(sub_dataset.size)\n",
    "    print(f'  {key}: {size} -> {property_list[key][\"long name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICSTBC': {'min': -2.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTCG': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTGN': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPS': {'min': 0.0, 'max': 67241.0, 'timesteps': set(), 'size': 533403},\n",
       " 'ICSTPB': {'min': 1.0, 'max': 533403.0, 'timesteps': set(), 'size': 533403},\n",
       " 'IPSTCS': {'min': 373.0, 'max': 533075.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTBT': {'min': 9.0, 'max': 9.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IPSTAC': {'min': 1.0, 'max': 1.0, 'timesteps': set(), 'size': 67241},\n",
       " 'IGNTID': {'min': 47.0, 'max': 47.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTJD': {'min': 39.0, 'max': 39.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTKD': {'min': 291.0, 'max': 291.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTZA': {'min': 0.0, 'max': 0.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTGT': {'min': 12.0, 'max': 12.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTFR': {'min': 533404.0, 'max': 533404.0, 'timesteps': set(), 'size': 1},\n",
       " 'IGNTNC': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'IGNTNS': {'min': 0.0, 'max': 533403.0, 'timesteps': set(), 'size': 2},\n",
       " 'ICTPS1': {'min': 1.0, 'max': 67238.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICTPS2': {'min': 3.0, 'max': 67240.0, 'timesteps': set(), 'size': 176572},\n",
       " 'ICNTDR': {'min': 1.0, 'max': 3.0, 'timesteps': set(), 'size': 176572},\n",
       " 'BLOCKSIZE': {'min': 0.0,\n",
       "  'max': 277.3068,\n",
       "  'timesteps': set(),\n",
       "  'size': 1600209},\n",
       " 'BLOCKDEPTH': {'min': 5092.376,\n",
       "  'max': 5818.083,\n",
       "  'timesteps': set(),\n",
       "  'size': 533403},\n",
       " 'NODES': {'min': 5081.534,\n",
       "  'max': 7282220.5,\n",
       "  'timesteps': set(),\n",
       "  'size': 1886853},\n",
       " 'BLOCKS': {'min': 1.0, 'max': 628951.0, 'timesteps': set(), 'size': 4267224},\n",
       " 'ISECTGEOM': {'min': -1.0,\n",
       "  'max': 533075.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 67242},\n",
       " 'BLOCKPVOL': {'min': 2000.1254,\n",
       "  'max': 92200.94,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'BVOL': {'min': 9696.793,\n",
       "  'max': 241620.36,\n",
       "  'timesteps': set(),\n",
       "  'size': 67241},\n",
       " 'WELLRADIUS': {'min': -100000000.0,\n",
       "  'max': -100000000.0,\n",
       "  'timesteps': set(),\n",
       "  'size': 1}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{p:grid_property_list[p] for p in grid_property_list if len(grid_property_list[p]['timesteps'])==0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHUNK_SIZE = 1200\n",
    "\n",
    "def expand_list(original_list, items=1):\n",
    "    expanded_list = []\n",
    "    for value in original_list:\n",
    "        value_shift = (value-1)*items\n",
    "        expanded_list.append(value_shift)\n",
    "        for new_value in range(value_shift + 1, value_shift + items):\n",
    "            expanded_list.append(new_value)\n",
    "    return expanded_list\n",
    "\n",
    "def get_dataset_data(dataset, values_list):\n",
    "    if not is_iterable(values_list):\n",
    "        return dataset[values_list]\n",
    "    x_ordered = list(set(values_list)).copy()\n",
    "    x_ordered.sort()\n",
    "    sub_x_ordered = np.array_split(x_ordered, int(len(x_ordered)/_CHUNK_SIZE)+1)\n",
    "    y_dict = dict()\n",
    "    for x in sub_x_ordered:\n",
    "        y = dataset[x]\n",
    "        for x,y in zip(x, y):\n",
    "            y_dict[x] = y        \n",
    "    return  np.array([y_dict[x] for x in values_list])\n",
    "\n",
    "def is_iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "    \n",
    "def get_cel_number(i,j,k, can_be_iterable=True):\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        return [ii + ni*(jj-1 + (kk-1)*nj) for (ii,jj,kk) in zip(i,j,k)]\n",
    "    return i + ni*(j-1 + (k-1)*nj)\n",
    "\n",
    "def get_nodes_index(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/BLOCKS']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        y = get_dataset_data(dataset, expand_list(i, 8))\n",
    "        return np.reshape(y, (-1, 8))      \n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return dataset[(i-1)*8:i*8]\n",
    "\n",
    "def get_cell_coordinates(i,j=None,k=None, can_be_iterable=True):\n",
    "    dataset = f['SpatialProperties/000000/GRID/NODES']\n",
    "    if can_be_iterable and is_iterable(i):\n",
    "        if j is not None:\n",
    "            i = get_cel_number(i,j,k)\n",
    "        nodes = get_nodes_index(i)\n",
    "        y = get_dataset_data(dataset, expand_list(nodes.flatten(), 3))\n",
    "        return y.reshape((len(i), 8, 3))\n",
    "    if j is not None:\n",
    "        i = get_cel_number(i,j,k)\n",
    "    return [dataset[(n-1)*3:n*3] for n in get_nodes_index(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:04.204510\n"
     ]
    }
   ],
   "source": [
    "size = 2000\n",
    "i_list = list(np.random.randint(low=1, high=ni, size=size))\n",
    "j_list = list(np.random.randint(low=1, high=nj, size=size))\n",
    "k_list = list(np.random.randint(low=1, high=nk, size=size))\n",
    "\n",
    "cells = get_cel_number(i_list,j_list,k_list)\n",
    "\n",
    "start_time = datetime.now()\n",
    "x = get_cell_coordinates(cells)\n",
    "end_time = datetime.now()\n",
    "print(f'Elapsed time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(func, size):\n",
    "    i_list = list(np.random.randint(low=1, high=ni, size=size))\n",
    "    j_list = list(np.random.randint(low=1, high=nj, size=size))\n",
    "    k_list = list(np.random.randint(low=1, high=nk, size=size))\n",
    "    cells = get_cel_number(i_list,j_list,k_list)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    x = func(cells)\n",
    "    end_time = datetime.now()\n",
    "    # print(f'{s} elemts: {end_time - start_time} ({(end_time - start_time)/s*1000} per 1000 elemts)')\n",
    "    return (end_time - start_time)/size*1000 \n",
    "\n",
    "def time_function_sens(func, arguments_sizes):\n",
    "    t = []\n",
    "    for s in arguments_sizes:\n",
    "        t.append(time_function(func, s))\n",
    "    return t\n",
    "\n",
    "def time_function_opt(func, min_val, max_val, fmin_val=None, fmax_val=None):\n",
    "    if fmin_val is None:\n",
    "        fmin_val = time_function(func, min_val)\n",
    "        print(f'{min_val} => {fmin_val}')\n",
    "    if fmax_val is None:\n",
    "        fmax_val = time_function(func, max_val)\n",
    "        print(f'{max_val} => {fmax_val}')\n",
    "    a_val = int((2*min_val + max_val)/3)\n",
    "    b_val = int((min_val + 2*max_val)/3)\n",
    "    if a_val == min_val or b_val == max_val:\n",
    "        if fmin_val < fmax_val:\n",
    "            return min_val\n",
    "        else:\n",
    "            return max_val\n",
    "    fa_val = time_function(func, a_val)\n",
    "    fb_val = time_function(func, b_val)\n",
    "    print(f'{a_val} => {fa_val}')\n",
    "    print(f'{b_val} => {fb_val}')\n",
    "    if fa_val < fb_val:\n",
    "        return time_function_opt(func, min_val, b_val, fmin_val, fb_val)\n",
    "    else:\n",
    "        return time_function_opt(func, a_val, max_val, fa_val, fmax_val)\n",
    "\n",
    "\n",
    "# t = time_function_sens(get_nodes_index, [100, 200, 500, 1000, 2000, 5000])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
